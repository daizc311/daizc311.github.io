[{"title":"Java Stream Reduce 注意事项","path":"Java Stream Reduce 注意事项/","text":"Java Stream Reduce 注意事项 👇出问题的代码，最终得到的List每个对象的属性都完全一样的，甚是邪门 1234567891011121314151617181920212223242526272829303132public List&lt;CallboxAppVersion&gt; listCAVbyObs(@NotNull String profile) &#123; // 略... return objectListing.getObjects().stream().map(obsObject -&gt; 略) .collect(Collectors.groupingBy( CallboxObsKeyMatcherResult::version, Collectors.reducing( new CallboxAppVersion(), (CallboxObsKeyMatcherResult mr) -&gt; &#123; var appVersion = new CallboxAppVersion(); appVersion.setName(&quot;Callbox&quot;); appVersion.setBrand(mr.brand()); appVersion.setVersion(mr.version()); appVersion.setType(mr.type()); if (mr.suffix().equals(&quot;zip&quot;)) &#123; appVersion.setZipKey(mr.objectKey()); &#125; else if (mr.suffix().equals(&quot;exe&quot;)) &#123; appVersion.setExeKey(mr.objectKey()); &#125; return appVersion; &#125;, (o1, o2) -&gt; &#123; o1.setName(o1.getName() == null ? o2.getName() : o1.getName()); o1.setVersion(o1.getVersion() == null ? o2.getVersion() : o1.getVersion()); o1.setBrand(o1.getBrand() == null ? o2.getBrand() : o1.getBrand()); o1.setType(o1.getType() == null ? o2.getType() : o1.getType()); o1.setExeKey(o1.getExeKey() == null ? o2.getExeKey() : o1.getExeKey()); o1.setZipKey(o1.getZipKey() == null ? o2.getZipKey() : o1.getZipKey()); return o1; &#125;) )) .values().stream().toList();&#125; 由于代码太过复杂，所以先对逻辑进行剥离，方便观察。 首先先对最复杂的Collectors.reducing()函数进行简化： Collectors被大量引入，所以进行静态import reducing()中的mapping部分是将MatcherResult变为CallboxAppVersion，我们抽象为CallboxAppVersion的constructor reducing()中的merge部分是将两个CallboxAppVersion合并为一个，我们抽象为fun merge() 👇剥离业务逻辑后的代码 123456789101112131415 public List&lt;CallboxAppVersion&gt; listCAVbyObs(@NotNull String profile) &#123; // 略... var collect = objectListing.getObjects().stream().map(obsObject -&gt; 略) .filter(Objects::nonNull) .filter(matcherResult -&gt; matcherResult.version() != null) .collect(Collectors.groupingBy( CallboxObsKeyMatcherResult::version, Collectors.reducing( new CallboxAppVersion(), CallboxAppVersion::new, CallboxAppVersion::merge ) )); return collect.values().stream().toList();&#125; 观察上面的代码，在return处下了断点，我发现map的key正常，但所有value的属性是一样的，我认为是mapping时出现了问题，随即调整结构，将reduce(new,mapping,merge)调整为mapping(mapping,reduce(new,merge))。 1234567891011public List&lt;CallboxAppVersion&gt; listCAVbyObs(@NotNull String profile) &#123; // 略... var collect = objectListing.getObjects().stream().map(obsObject -&gt; 略) .collect(Collectors.groupingBy( CallboxObsKeyMatcherResult::version, mapping(CallboxObsKeyMatcherResult::new, reducing(new CallboxAppVersion(), CallboxAppVersion::merge) ) )); return collect.values().stream().toList();&#125; 保持return处的断点，再次运行后，结果仍然一致，这个时候我发现collect的values中，所有的value是同一个引用，而代码中有一个new CallboxAppVersion()作为reducing的初始值，这十分可疑。但这个new在lambda中，就算使用调试器也不好直接观察，于是到CallboxAppVersion的constructor和merge中下断点。 12345678910111213141516171819202122232425262728293031public class CallboxAppVersion &#123; private String name; private String brand; private Version version; private String type; private String zipKey; private String exeKey; public CallboxAppVersion(CallboxObsKeyMatcherResult mr) &#123; this.setName(&quot;Callbox&quot;); this.setBrand(mr.brand()); this.setVersion(mr.version()); this.setType(mr.type()); if (mr.suffix().equals(&quot;zip&quot;)) &#123; this.setZipKey(mr.objectKey()); &#125; else if (mr.suffix().equals(&quot;exe&quot;)) &#123; this.setExeKey(mr.objectKey()); &#125; &#125; public CallboxAppVersion merge(CallboxAppVersion that) &#123; this.setName(that.getName() == null ? this.getName() : that.getName()); this.setBrand(that.getBrand() == null ? this.getBrand() : that.getBrand()); this.setVersion(that.getVersion() == null ? this.getVersion() : that.getVersion()); this.setType(that.getType() == null ? this.getType() : that.getType()); this.setZipKey(that.getZipKey() == null ? this.getZipKey() : that.getZipKey()); this.setExeKey(that.getExeKey() == null ? this.getExeKey() : that.getExeKey()); return this; &#125;&#125; 👇猛然发现在merge方法中return了this，并没有复制实体，于是修改merge实现 12345678910public CallboxAppVersion merge(CallboxAppVersion that) &#123; CallboxAppVersion merged = new CallboxAppVersion(); merged.setName(that.getName() == null ? this.getName() : that.getName()); merged.setBrand(that.getBrand() == null ? this.getBrand() : that.getBrand()); merged.setVersion(that.getVersion() == null ? this.getVersion() : that.getVersion()); merged.setType(that.getType() == null ? this.getType() : that.getType()); merged.setZipKey(that.getZipKey() == null ? this.getZipKey() : that.getZipKey()); merged.setExeKey(that.getExeKey() == null ? this.getExeKey() : that.getExeKey()); return merged;&#125; 修改merge后，返回结果正常。判定是new CallboxAppVersion()的问题，结合reducing(new CallboxAppVersion(), CallboxAppVersion::new, CallboxAppVersion::merge)的写法，我们可以反向推断lambda在这里的实现 👇伪代码 1234567891011groupingBy(key,values)&#123; reducedValue = reducing(firstobj,fun mapping,fun merge)&#123; var current = firstobj for value of values: next = mapping(value) current = merge(first,next) # 其中这个current被复用了，就是我new的那个CallboxAppVersion对象 retrun current &#125; retrun (key,reducedValue)&#125; lambda用多了老是会觉得对象都是final的不可变也不复用，就感觉这个reduce的设计有点反直觉，如果这个current的变量设计为一个creator函数就不会有问题了，就像下面这样👇伪代码 1234567891011groupingBy(key,values)&#123; reducedValue = reducing(fun firstCretor,fun mapping,fun merge)&#123; # 这个current每次都传新对象，就不会有这个问题了 var current = firstCretor() for value of values: next = mapping(value) current = merge(first,next) retrun current &#125; retrun (key,reducedValue)&#125; 对应代码 12345678910111213141516171819202122232425262728293031// 原实现@SuppressWarnings(&quot;unchecked&quot;)private static &lt;T&gt; Supplier&lt;T[]&gt; boxSupplier(T identity) &#123; return () -&gt; (T[]) new Object[]&#123;identity&#125;;&#125;// 注意到第一个参数名是identity，语义上感觉这个就应该传入一个独一无二的变量才对public static &lt;T, U&gt; Collector&lt;T, ?, U&gt; reducing(U identity, Function&lt;? super T, ? extends U&gt; mapper, BinaryOperator&lt;U&gt; op) &#123; return new CollectorImpl&lt;&gt;( // 这里参数列表对不上，还起了个数组来hold住identity，不知道这么实现是为了什么？ boxSupplier(identity), (a, t) -&gt; &#123;a[0] = op.apply(a[0], mapper.apply(t));&#125;, (a, b) -&gt; &#123; a[0] = op.apply(a[0], b[0]); return a; &#125;, a -&gt; a[0], CH_NOID);&#125;// 期望实现public static &lt;T, U&gt; Collector&lt;T, ?, U&gt; reducing(Supplier&lt;U&gt; identityCreator, Function&lt;? super T, ? extends U&gt; mapper, BinaryOperator&lt;U&gt; op) &#123; // 第一个参数如果改成Supplier就可以每次生成新对象，避免上述问题了 return new CollectorImpl&lt;&gt;( identityCreator, (a, t) -&gt; &#123;a[0] = op.apply(a[0], mapper.apply(t));&#125;, (a, b) -&gt; &#123; a[0] = op.apply(a[0], b[0]); return a; &#125;, a -&gt; a[0], CH_NOID);&#125; 其他优化 发现CallboxAppVersion类中的merge方法完全可以封装成接口，这个肯定很常用的，而jdk里没带Mergeable接口，Spring带的又没泛型，那就自行封装一个，然后CallboxAppVersion去实现一下。 123interface Mergeable&lt;T&gt; &#123; T merge(T that);&#125;"},{"title":"[Csharp]Class与RecordStruct","path":"[Csharp]Class与Record与Struct/","text":"示例代码 为了测试在C#中Class、Struct、Record三者的区别，建立了以下测试类。每个类中，分别建立了一个字段，一个自动属性，一个仅init的自动属性和一个具有私有setter的自动属性，其中Record额外建立了一个记录属性。 1234567891011121314151617181920212223242526public class ClassA &#123; public string field; public string Prop &#123; get; set; &#125; public string PropInit &#123; get; init; &#125; public string PropPrivateSet &#123; get; private set; &#125; public override string ToString() &#123; return $&quot;&#123;nameof(this.field)&#125;: &#123;this.field&#125;, &#123;nameof(this.Prop)&#125;: &#123;this.Prop&#125;, &#123;nameof(this.PropInit)&#125;: &#123;this.PropInit&#125;, &#123;nameof(this.PropPrivateSet)&#125;: &#123;this.PropPrivateSet&#125;&quot;; &#125;&#125;public struct StructA &#123; public string field; public string Prop &#123; get; set; &#125; public string PropInit &#123; get; init; &#125; public string PropPrivateSet &#123; get; private set; &#125; public override string ToString() &#123; return $&quot;&#123;nameof(this.field)&#125;: &#123;this.field&#125;, &#123;nameof(this.Prop)&#125;: &#123;this.Prop&#125;, &#123;nameof(this.PropInit)&#125;: &#123;this.PropInit&#125;, &#123;nameof(this.PropPrivateSet)&#125;: &#123;this.PropPrivateSet&#125;&quot;; &#125;&#125;public record RecordA(string PropRc) &#123; public string field; public string Prop &#123; get; set; &#125; public string PropInit &#123; get; init; &#125; public string PropPrivateSet &#123; get; private set; &#125;&#125; 反序列化测试设计一个反序列化的测试类，对三种类型分别进行反序列化测试，三种类型均可以正常进行反序列化。 12345678910111213141516171819202122232425262728293031using Newtonsoft.Json;using Newtonsoft.Json.Converters;using Newtonsoft.Json.Linq;using Newtonsoft.Json.Serialization;using System;string str = &quot;&quot;&quot; &#123; &quot;field&quot;:&quot;Field&quot;, &quot;prop&quot;:&quot;Prop&quot;, &quot;propInit&quot;:&quot;Init Prop&quot;, &quot;propPrivateSet&quot;:&quot;Private Setter Prop&quot;, &quot;PropRc&quot;:&quot;Enum Main Constructor Param&quot; &#125; &quot;&quot;&quot;;var deserializeObject = JsonConvert.DeserializeObject&lt;JObject&gt;(str);var classA = deserializeObject.ToObject&lt;ClassA&gt;();var structA = deserializeObject.ToObject&lt;StructA&gt;();var recordA = deserializeObject.ToObject&lt;RecordA&gt;();var classB = JsonConvert.DeserializeObject&lt;ClassA&gt;(str);var structB= JsonConvert.DeserializeObject&lt;StructA&gt;(str);var recordB= JsonConvert.DeserializeObject&lt;RecordA&gt;(str);Console.WriteLine(classA);Console.WriteLine(structA);Console.WriteLine(recordA);Console.WriteLine(classB);Console.WriteLine(structB);Console.WriteLine(recordB); struct是值类型，是不可变的"},{"title":"[Csharp]Task相关","path":"[Csharp]Task相关/","text":"async与await示例代码 1234567891011121314151617181920212223public async static void test() &#123; XmlConfigurator.Configure(new System.IO.FileInfo(&quot;log4net.config&quot;)); TaskCompletionSource&lt;string&gt; source = new TaskCompletionSource&lt;string&gt;(); new Thread(o =&gt; &#123; log.Info(&quot;Thread Sleep&quot;); Thread.Sleep(1000); log.Info(&quot;Thread TrySetResult&quot;); // source.TrySetResult(&quot;6666666666&quot;); // source.TrySetCanceled(); source.TrySetException(new Exception(&quot;666&quot;)); &#125;).Start(); log.Info(&quot;Start await&quot;); try &#123; string waitAsync = await source.Task.WaitAsync(new TimeSpan(0, 0, 5)); log.Info(&quot;End await =&gt; &quot; + waitAsync); // string s = await test2(source); &#125; catch (TimeoutException e) &#123; log.Info(&quot;TimeoutException&quot;, e); &#125; catch (TaskCanceledException e) &#123; log.Info(&quot;TaskCanceledException&quot;, e); &#125; log.Info(&quot;End&quot;);&#125; Task.Wait123456789101112131415161718192021222324252627282930public static void testWait() &#123; XmlConfigurator.Configure(new System.IO.FileInfo(&quot;log4net.config&quot;)); TaskCompletionSource&lt;string&gt; source = new TaskCompletionSource&lt;string&gt;(); new Thread(o =&gt; &#123; log.Info(&quot;Thread Sleep&quot;); Thread.Sleep(3000); log.Info(&quot;Thread TrySetResult&quot;); // source.TrySetResult(&quot;6666666666&quot;); source.TrySetCanceled(); // source.TrySetException(new Exception()); &#125;).Start(); log.InfoFormat(&quot;Start Wait&quot;); try &#123; bool wait = source.Task.Wait(5000); log.InfoFormat(&quot;Wait:&#123;0&#125;&quot;, wait); if (wait) &#123; if (source.Task.Status == TaskStatus.RanToCompletion) &#123; log.InfoFormat(&quot;Result:&#123;0&#125;&quot;, source.Task.Result); &#125; else if (source.Task.Status == TaskStatus.Faulted) &#123; log.InfoFormat(&quot;Exception:&#123;0&#125;&quot;, source.Task.Exception); &#125; &#125; else &#123; log.InfoFormat(&quot;Timeout&quot;); &#125; &#125; catch (Exception e) &#123; log.InfoFormat(&quot;Exception: &#123;0&#125;=&gt;&#123;1&#125;&quot;, e.GetType(),e.InnerException.GetType()); &#125;&#125;"},{"title":"[Csharp]WPF集成Sqlite与数据库加解密","path":"[Csharp]WPF集成Sqlite与数据库加解密/","text":"一句话总结关于依赖安装抽象层选用Entity Framework Core，只能安装3.x.x版本的。因为.NETFramework是传统框架，只支持到3版本，不然就只能装大版本为6的Entity Framework(EF6)，但是由于EF6已经不积极维护了，综合考虑还是更建议装EFC3。 关于数据库加密SQLite原版没有实现数据库加密，要加密就只能选用其他的SqLite发行版，他们的加密方式各异，用谁创建的数据库就得用谁读写。推荐SQLiteStudio工具，可以选择很多加解密方式。 关于WPF集成SqLite加密巨硬官方已经出了例子了. 123dotnet remove package Microsoft.Data.Sqlite # 这是个集成包，删掉dotnet add package Microsoft.Data.Sqlite.Core # 这才是微软对Sqlite的封装核心dotnet add package SQLitePCLRaw.bundle_e_sqlcipher # 这个真正想使用的Sqlite发行版的bundle包 修改ConnectString即可 1234567# 记得别直接字符串拼，到时候被人注入了SqliteConnectionStringBuilder sqliteConnectionStringBuilder = new SqliteConnectionStringBuilder &#123; Password = &quot;xxxxxxxxxx&quot;, Mode = SqliteOpenMode.ReadWriteCreate, DataSource = &quot;xxxxxxx.db&quot; &#125;;var connectString = sqliteConnectionStringBuilder.ToString(); 参考资料 (1#)在 Windows 应用中使用 SQLite 数据库 (2#)Problems trying to encrypt SQLite database on UWP (3#)加密 - Microsoft.Data.Sqlite (4#)Incompatible SQLCipher 4 database (5#)SQLiteStudio WPF应用集成数据库通过阅读文档(1#)，大概了解了下DotNet的ORM生态,基本上就是用巨硬自家的解决方案Entity Framework。然后我打开Nuget，开始安装依赖，很快就遇到了第一个问题没法安装 为什么？因为这个包是Entity Framework Core，是给DotNet Core使用的对象映射框架。而我们的基础框架是.NETFramework 4.8.1，只能用传统的Entity Framework，可恶的巨硬。"},{"title":"[Csharp]可为空的类型","path":"[Csharp]可为空的类型/","text":"[Csharp]可为空的类型一句话总结值类型的不能?操作符的是通过Nullable&lt;T&gt;包装实现的，而引用类型由于本来就可以为空，所以?操作符只是个供编译器推断的标识而已。 参考资料 可为 null 的引用类型 可为 null 的值类型 12345// 此处输出为 Nullable[int]Console.WriteLine($&quot;int?:\\t&#123;typeof(int?)&#125;&quot;);// 此处输出为 stringConsole.WriteLine($&quot;obj?:\\t&#123;typeof(string?)&#125;&quot;); 可空值类型一句话总结:int?和int是两个不一样的类型，int?其实是Nullable&lt;int&gt;的语法糖，因为值类型是直接指向具体值的，因此不能直接被指向null,必须经过包装。 12345int aNn = null; // Error CS0037 : 无法将 null 转换为“int”，因为后者是不可为 null 的值类型int? a = null; // 其实是 Nullable&lt;int&gt; = new Nullable&lt;&gt;(); Console.WriteLine(a.Value); // 输出 nullConsole.WriteLine(a.HasValue); // 输出 true 可空引用类型一句话总结:BaseWsRequest&lt;object&gt;?和 BaseWsRequest&lt;object&gt;其实是同一个类型，string和string?也一样。因为他们都是引用类型，可以指向null，因此编译器并不会对他们额外进行包装。 1234567string? str = null;string strNn = null;// 引用类型可以被声明为空引用BaseWsRequest&lt;object&gt;? obj = null;// 引用类型可以为nullBaseWsRequest&lt;object&gt; objNn = null;"},{"title":"[Csharp]循环链表封装","path":"[Csharp]循环链表List封装/","text":"[Csharp]循环链表封装要求 需要具有线程安全特性 可以直接找出上一个、当前值和下一个值 思路一开始是打算直接拿LinkedList改改的，打算直接把LinkedListNode首尾连起来，然后直接用就是了。但随即发现一个问题：要是谁谁谁不小心for了一下这list，那还得了？而且线程安全也没法保证啊。设计一个CreateCircularList，通过CreateCircularIterator方法生产一个Iterator,再去迭代这个Iterator就没问题了。但随后也发现一个问题，这不够通用，我必须new一个CreateCircularList， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950using System.Collections.Generic;#pragma warning disable CS0219 // 变量已被赋值，但从未使用过它的值namespace Wpf481.Utils;public class CircularLinkedIterator&lt;TData&gt; where TData : struct &#123; private readonly CircularLinkedList&lt;TData&gt; _list; public CircularLinkedIterator(ICollection&lt;TData&gt; collection) &#123; _list = new CircularLinkedList&lt;TData&gt;(collection); &#125; public int CurrentIndex &#123; get; private set; &#125; = -1; public void Next() &#123; lock (this) &#123; if (_list.Count == 0) &#123; CurrentIndex = -1; return; &#125; var index = CurrentIndex + 1; CurrentIndex = index == _list.Count ? 0 : index; &#125; &#125; public TData? NextItem &#123; get &#123; return _list.GetNodeByIndex(CurrentIndex + 1)?.Value; &#125; &#125; public TData? PreviousItem =&gt; _list.GetNodeByIndex(CurrentIndex - 1)?.Value; public TData? CurrentItem =&gt; _list.GetNodeByIndex(CurrentIndex)?.Value; private class CircularLinkedList&lt;T&gt; : LinkedList&lt;T&gt; where T : struct &#123; internal CircularLinkedList(IEnumerable&lt;T&gt; collection) : base(collection) &#123; &#125; internal LinkedListNode&lt;T&gt;? GetNodeByIndex(int index) &#123; if (Count == 0) &#123; return null; &#125; int realIndex = (Count + index) % Count; var current = First; for (int i = 0; i &lt; realIndex; i++) &#123; current = current?.Next ?? First; &#125; return current; &#125; &#125;&#125; 单元测试123456789101112131415161718192021222324252627282930313233343536public class CircularLinkedListTest &#123; public static void test() &#123; LoggerFactory.Create(builder =&gt; &#123; &#125;).CreateLogger&lt;CircularLinkedListTest&gt;(); var list = new List&lt;int&gt;(); var iterator = new CircularLinkedIterator&lt;int&gt;(list); for (int i = 0; i &lt; 3; i++) &#123; Console.WriteLine( $&quot;[&#123;iterator.CurrentIndex&#125;]\\tlast: &#123;iterator.PreviousItem&#125; \\t current: &#123;iterator.CurrentItem&#125;\\t next: &#123;iterator.NextItem&#125;&quot;); iterator.Next(); &#125; for (int i = 1; i &lt;= 2; i++) &#123; list.Add(i); &#125; iterator = new CircularLinkedIterator&lt;int&gt;(list); for (int i = 0; i &lt; 10; i++) &#123; Console.WriteLine( $&quot;[&#123;iterator.CurrentIndex&#125;]\\tlast: &#123;iterator.PreviousItem&#125; \\t current: &#123;iterator.CurrentItem&#125;\\t next: &#123;iterator.NextItem&#125;&quot;); iterator.Next(); &#125; list.Clear(); iterator = new CircularLinkedIterator&lt;int&gt;(list); for (int i = 0; i &lt; 3; i++) &#123; Console.WriteLine( $&quot;[&#123;iterator.CurrentIndex&#125;]\\tlast: &#123;iterator.PreviousItem&#125; \\t current: &#123;iterator.CurrentItem&#125;\\t next: &#123;iterator.NextItem&#125;&quot;); iterator.Next(); &#125; &#125; &#125;&#125;"},{"title":"集群爆炸，但是修好了","path":"集群爆炸，但是修好了/","text":"周一到公司来一看，本地集群连不上了，据说是周末停电关了服务器造成的。既然环境爆炸那啥也干不了只能挂机了， 那可不行，赶快修好了开始干活。 首先ssh能通，至少虚拟机没问题，试试docker ps。有反应，但容器全都停在pause上。同时kubectl get node卡住没有回应。1234567[root@vmw253 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 949258e9135c 37c6aeb3663b &quot;kube-controller-man…&quot; 3 hours ago Up 3 hours k8s_kube-controller-manager_kube-controller-manager-vmw253_kube-system_b53e0e776bdd23d5be83ec232a105a76_1036 4a3a50cbf1fb registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1 &quot;/pause&quot; 3 hours ago Up 3 hours k8s_POD_kube-controller-manager-vmw253_kube-system_b53e0e776bdd23d5be83ec232a105a76_11 89aa599bc953 registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1 &quot;/pause&quot; 3 hours ago Up About an hour k8s_POD_kube-apiserver-vmw253_kube-system_6aa730f99776180fbac39af544cc5c43_11 76914665acbd 56c5af1d00b5 &quot;kube-scheduler --au…&quot; 3 hours ago Up 3 hours k8s_kube-scheduler_kube-scheduler-vmw253_kube-system_ceb9697816522e2427509f5707b24a58_1007 8248bd5e395d registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1 &quot;/pause&quot; 3 hours ago Up 3 hours k8s_POD_kube-scheduler-vmw253_kube-system_ceb9697816522e2427509f5707b24a58_11 求助运维老哥，老哥看了下现场，说api-server不见了，可能是etcd爆炸，叫检查下etcd。因为使用kubesphere脚本部署的，所以也不知道etcd怎么启动的，检查了一圈，没有发现etcd的影子。 ps -ef时意外发现系统定时任务正在拉起etcd的备份任务，由此确定etcd应该是由systemctl管理，随后crontab -l结果如下 1234[root@vmw253 ~]# crontab -l*/5 * * * * /usr/sbin/ntpdate ntp3.aliyun.com &amp;&gt;/dev/null0 3 * * * ps -A -ostat,ppid | grep -e &#x27;^[Zz]&#x27; | awk &#x27;&#123;print &#125;&#x27; | xargs kill -HUP &gt; /dev/null 2&gt;&amp;1*/30 * * * * sh /usr/local/bin/kube-scripts/etcd-backup.sh 检查etcd-backup.sh，发现了备份所在地，从环境变量中取出了数据目录1234567891011# 此行声明了备份地址BACKUP_DIR=&quot;/var/backups/kube_etcd/etcd-$(date +%Y-%m-%d-%H-%M-%S)&quot;# 此行引用了数据目录变量export ETCDCTL_API=2;$ETCDCTL_PATH backup --data-dir $ETCD_DATA_DIR --backup-dir $BACKUP_DIR# 此行调用etcdctl进行备份 (重要-1)&#123; export ETCDCTL_API=3;$ETCDCTL_PATH --endpoints=&quot;$ENDPOINTS&quot; snapshot save $BACKUP_DIR/snapshot.db \\ --cacert=&quot;$ETCDCTL_CA_FILE&quot; \\ --cert=&quot;$ETCDCTL_CERT&quot; \\ --key=&quot;$ETCDCTL_KEY&quot;&#125; &gt; /dev/null 检查etcd-backup.sh，发现从环境变量中取出了备份地址，然后从sytemctl status etcd中取到etcd配置，再从etcd配置取到env文件地址(&#x2F;etc&#x2F;etcd.env)123456789101112131415161718192021222324252627# 因为写的时候已经把etcd修好了，所以Active是running [root@vmw253 ~]# systemctl status etcd ● etcd.service - etcd Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: disabled) Active: active (running) since 一 2023-07-10 15:06:18 CST; 22min ago Main PID: 36781 (etcd) Tasks: 25 Memory: 97.8M CGroup: /system.slice/etcd.service └─36781 /usr/local/bin/etcd [root@vmw253 ~]# cat /etc/systemd/system/etcd.service [Unit] Description=etcd After=network.target [Service] User=root Type=notify EnvironmentFile=/etc/etcd.env ExecStart=/usr/local/bin/etcd NotifyAccess=all RestartSec=10s LimitNOFILE=40000 Restart=always [Install] WantedBy=multi-user.target 检查env文件,得到关键的数据目录地址1ETCD_DATA_DIR=/var/lib/etcd 停止etcd，移除数据目录12systemctl stop etcdmv /var/lib/etcd /var/lib/etcd.bak 从定时任务触发的命令中发现了etcd的命令行客户端:etcdctl，使用–help看看他的用法，发现一个snapshot restore指令1234567891011121314151617181920212223242526272829303132333435363738[root@vmw253 ~]# etcdctl snapshotNAME: snapshot - Manages etcd node snapshotsUSAGE: etcdctl snapshot &lt;subcommand&gt; [flags]API VERSION: 3.4COMMANDS: restore Restores an etcd member snapshot to an etcd directory save Stores an etcd node backend snapshot to a given file status Gets backend snapshot status of a given fileOPTIONS:-h, --help[=false] help for snapshotGLOBAL OPTIONS: --cacert=&quot;&quot; verify certificates of TLS-enabled secure servers using this CA bundle --cert=&quot;&quot; identify secure client using this TLS certificate file --command-timeout=5s timeout for short running command (excluding dial timeout) --debug[=false] enable client-side debug logging --dial-timeout=2s dial timeout for client connections-d, --discovery-srv=&quot;&quot; domain name to query for SRV records describing cluster endpoints --discovery-srv-name=&quot;&quot; service name to query when using DNS discovery --endpoints=[127.0.0.1:2379] gRPC endpoints --hex[=false] print byte strings as hex encoded strings --insecure-discovery[=true] accept insecure SRV records describing cluster endpoints --insecure-skip-tls-verify[=false] skip server certificate verification (CAUTION: this option should be enabled only for testing purposes) --insecure-transport[=true] disable transport security for client connections --keepalive-time=2s keepalive time for client connections --keepalive-timeout=6s keepalive timeout for client connections --key=&quot;&quot; identify secure client using this TLS key file --password=&quot;&quot; password for authentication (if this option is used, --user option shouldn&#x27;t include password) --user=&quot;&quot; username[:password] for authentication (prompt if password is not supplied)-w, --write-out=&quot;simple&quot; set the output format (fields, json, protobuf, simple, table) 通过备份脚本中的命令(重要-1)和上一步中的提示，反向拼接还原命令1/usr/local/bin/etcdctl --endpoints=https://192.168.20.233:2379 snapshot restore /var/backups/kube_etcd/etcd-2023-07-08-00-00-01/snapshot.db --cacert=/etc/ssl/etcd/ssl/ca.pem --cert=/etc/ssl/etcd/ssl/admin-vmw253.pem --key=/etc/ssl/etcd/ssl/admin-vmw253-key.pem 很遗憾报了错，说数据目录已存在，旁边运维老哥提示加data-dir参数，于是把刚才得到的参数拼接进去1/usr/local/bin/etcdctl --endpoints=https://192.168.20.233:2379 snapshot restore /var/backups/kube_etcd/etcd-2023-07-08-00-00-01/snapshot.db --cacert=/etc/ssl/etcd/ssl/ca.pem --cert=/etc/ssl/etcd/ssl/admin-vmw253.pem --key=/etc/ssl/etcd/ssl/admin-vmw253-key.pem 这次不遗憾，看起来成功了，随后启动etcd，未见明显异常。kubectl 也马上返回了结果，随后集群很快恢复了 12345678910111213[root@vmw253 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES949258e9135c 37c6aeb3663b &quot;kube-controller-man…&quot; 3 hours ago Up 3 hours k8s_kube-controller-manager_kube-controller-manager-vmw253_kube-system_b53e0e776bdd23d5be83ec232a105a76_10364a3a50cbf1fb registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1 &quot;/pause&quot; 3 hours ago Up 3 hours k8s_POD_kube-controller-manager-vmw253_kube-system_b53e0e776bdd23d5be83ec232a105a76_1189aa599bc953 registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1 &quot;/pause&quot; 3 hours ago Up 54 minutes k8s_POD_kube-apiserver-vmw253_kube-system_6aa730f99776180fbac39af544cc5c43_1176914665acbd 56c5af1d00b5 &quot;kube-scheduler --au…&quot; 3 hours ago Up 3 hours k8s_kube-scheduler_kube-scheduler-vmw253_kube-system_ceb9697816522e2427509f5707b24a58_10078248bd5e395d registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1 &quot;/pause&quot; 3 hours ago Up 3 hours k8s_POD_kube-scheduler-vmw253_kube-system_ceb9697816522e2427509f5707b24a58_11[root@vmw253 ~]# systemctl start etcd[root@vmw253 ~]# kubectl get nodeNAME STATUS ROLES AGE VERSIONvmw253 Ready control-plane,master,worker 525d v1.23.0vmw254 Ready worker 525d v1.23.0vmw255 Ready worker 525d v1.23.0 居然修好了，真实可喜可贺呢:-D"},{"title":"Bash脚本经验之谈","path":"Bash脚本经验之谈/","text":"最近将CI&#x2F;CD从Gitlab迁移到我自己写的CI&#x2F;CD平台(自豪),在切换期间,需要使用脚本打通两个系统,于是乎这几天都在写bash脚本,真的快写吐了,各种命令语法花里胡哨,超简单的操作都需要绕半天才能成功.总的来说就是’使用各种不规范的写法调用各种东拼西凑来的工具来处理各种稀奇古怪的数据’.写的过程中也积累了不少经验教训,做个笔记分享一下（虽然也没人看）. 总结的一些教训 赋值语句等号后别带空格 123456root@7f1ca1fb0b2e:/# A = 666bash: A: command not foundroot@7f1ca1fb0b2e:/# A=666root@7f1ca1fb0b2e:/# echo $A666root@7f1ca1fb0b2e:/# 注: 写快了很容易犯低超低级错误 使用$符号取值时,单引号中的值不会计算: 1234567root@7f1ca1fb0b2e:/# A=666root@7f1ca1fb0b2e:/# echo $A666root@7f1ca1fb0b2e:/# echo &quot;$A&quot;666root@7f1ca1fb0b2e:/# echo &#x27;$A&#x27;$A 注: 超长字符串时注意需要分辨 多行语句时,切记检查转义符\\后有无空格 1234567root@7f1ca1fb0b2e:/# echo \\&gt; $A666root@7f1ca1fb0b2e:/# echo \\ root@7f1ca1fb0b2e:/# $Abash: 666: command not found 注: 答应我在vscode里写好了再粘贴过去好不? 别在单引号字符串里使用转义符 12345678910root@7f1ca1fb0b2e:/# echo asd\\&gt; dsaasddsaroot@7f1ca1fb0b2e:/# echo &quot;asd\\&gt; dsa&quot;asddsaroot@7f1ca1fb0b2e:/# echo &#x27;asd\\dsa&#x27;asd\\dsa 注: 眼睛都看直了没看出来问题,最后发现是个单引号 使用if块时,注意前后留空格 12345root@7f1ca1fb0b2e:/# if [[-z &quot;$UNIT_TEST&quot; ]] ;then echo &quot;true&quot;;else echo &quot;false&quot;;fi;bash: [[-z: command not foundfalseroot@7f1ca1fb0b2e:/# if [[ -z &quot;$UNIT_TEST&quot; ]] ;then echo &quot;true&quot;;else echo &quot;false&quot;;fi;true jq取值时,直接取出的值是jsonFormat的,需要加-r参数取原始值 1234root@7f1ca1fb0b2e:/# echo &#x27;&#123;&quot;key&quot;:&quot;value&quot;&#125;&#x27;|jq .key&quot;value&quot;root@7f1ca1fb0b2e:/# echo &#x27;&#123;&quot;key&quot;:&quot;value&quot;&#125;&#x27;|jq -r .keyvalue 注: 用之前先看看--help吧,求你了 使用jq拼接json最好的办法是用模板字符串(参数能够确定时) 123456789root@7f1ca1fb0b2e:/# PARAM=$( jq -n \\--arg beam_projectKey &quot;$beam_projectKey&quot;\\--arg beam_version &quot;$beam_version&quot;\\--arg beam_branch &quot;$beam_branch&quot;\\--arg beam_description &quot;$beam_description&quot;\\--arg beam_commitHash &quot;$beam_commitHash&quot;\\--arg beam_imageTag &quot;$beam_imageTag&quot; \\ &#x27;&#123;projectKey:$beam_projectKey,version: $beam_version,branch: $beam_branch,description: $beam_description,commitHash: $beam_commitHash,imageTag: $beam_imageTag,createUserId: &quot;USR-000000&quot;,createUserName: &quot;GitLab-CI&quot;&#125;&#x27;\\) 注: 千万别想着直接用jq动态插入&#x2F;替换值,真的很累 吸取的一些经验 多使用转义换行,活用括号分组,空格多加几个,以增加可读性(可读性仍然很低) 12345678echo &#x27;推送到Beam[本地]&#x27; &amp;&amp; \\RESULT=$(curl -s -XPOST &quot;http://192.167.20.38:8888/artifact/save&quot; \\ -H &quot;Accept: application/json&quot; \\ -H &quot;Content-Type: application/json&quot; \\ -H &quot;Auth: ******&quot; \\ --data-raw &quot;$PARAM&quot; --compressed) &amp;&amp; \\echo $RESULT|jq . || \\echo &#x27;[本地]Beam服务未启动&#x27; 上面这行指令由3个指令连接而成,关键地方做了换行并添加空格,看起来更有层次感. 使用&amp;&amp;进行指令连接,最后使用||兜底,相当于做了个try-catch.使得这行指令的返回值始终为’0’ 写流水线时不要头铁直接启动流水线进行调试,使用shell反弹将流水线中的bash反弹到本机进行调试,最后一次性将命令粘进脚本中,这样更省时间. 能写python不写bash,如果流水线由自己控制,那尽量保证镜像中带一个python环境,不要在乎那点大小,能快速出活才是最关键的. 如果bash脚本需要定义在yaml文件中,遇到长指令的时候最好使用|文本块放置 12345678910111213aaa: bbb: - echo start - | echo &#x27;推送到Beam[本地]&#x27; &amp;&amp; \\ RESULT=$(curl -s -XPOST &quot;http://192.167.20.38:8888/artifact/save&quot; \\ -H &quot;Accept: application/json&quot; \\ -H &quot;Content-Type: application/json&quot; \\ -H &quot;Auth: ******&quot; \\ --data-raw &quot;$PARAM&quot; --compressed) &amp;&amp; \\ echo $RESULT|jq . || \\ echo &#x27;[本地]Beam服务未启动&#x27; - echo end"},{"title":"PostgreSql单表存储多关联关系","path":"PostgreSql单表存储多关联关系/","text":"单表存储多关联关系需求是product、project、pipeline三个实体各自和互相都会互相关联，用于存储多个键值对。如果是标准数据库设计就需要6张表来存储： product_kv project_kv pipeline_kv product_project_kv project_pipeline_kv pipeline_product_kv 使用bit存储对象关联关系这里采用单表+二进制运算的方式来存储这一数据: 123456789CREATE TABLE &quot;public&quot;.&quot;variable&quot; ( &quot;type&quot; bit(3) NOT NULL, &quot;1_product_id&quot; varchar(255) NOT NULL DEFAULT &#x27;&#x27;::character varying, &quot;2_project_id&quot; varchar(255) NOT NULL DEFAULT &#x27;&#x27;::character varying, &quot;3_pipeline_id&quot; varchar(255) NOT NULL DEFAULT &#x27;&#x27;::character varying, &quot;v_key&quot; varchar(255) COLLATE &quot;pg_catalog&quot;.&quot;default&quot; NOT NULL, &quot;v_value&quot; text COLLATE &quot;pg_catalog&quot;.&quot;default&quot; NOT NULL, CONSTRAINT &quot;variable_pkey&quot; PRIMARY KEY (&quot;type&quot;, &quot;1_product_id&quot;, &quot;2_project_id&quot;, &quot;3_pipeline_id&quot;)); 用type字段来标识具体是那两个对象产生了关联, 1234bit(3)0 product关联位0 project关联位0 pipeline关联位 type&#x3D;b’100’时，该kv值属于product type&#x3D;b’010’时，该kv值属于project type&#x3D;b’001’时，该kv值属于pipeline type&#x3D;b’110’时，该kv值属于product与project的关联 以此类推… 查询方式准备数据 1234567INSERT INTO &quot;public&quot;.&quot;variable&quot; (&quot;type&quot;, &quot;1_product_id&quot;, &quot;2_project_id&quot;, &quot;3_pipeline_id&quot;, &quot;v_key&quot;, &quot;v_value&quot;) VALUES (&#x27;000&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;1&#x27;, &#x27;1&#x27;);INSERT INTO &quot;public&quot;.&quot;variable&quot; (&quot;type&quot;, &quot;1_product_id&quot;, &quot;2_project_id&quot;, &quot;3_pipeline_id&quot;, &quot;v_key&quot;, &quot;v_value&quot;) VALUES (&#x27;010&#x27;, &#x27;&#x27;, &#x27;1&#x27;, &#x27;&#x27;, &#x27;1&#x27;, &#x27;1&#x27;);INSERT INTO &quot;public&quot;.&quot;variable&quot; (&quot;type&quot;, &quot;1_product_id&quot;, &quot;2_project_id&quot;, &quot;3_pipeline_id&quot;, &quot;v_key&quot;, &quot;v_value&quot;) VALUES (&#x27;001&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;);INSERT INTO &quot;public&quot;.&quot;variable&quot; (&quot;type&quot;, &quot;1_product_id&quot;, &quot;2_project_id&quot;, &quot;3_pipeline_id&quot;, &quot;v_key&quot;, &quot;v_value&quot;) VALUES (&#x27;111&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;);INSERT INTO &quot;public&quot;.&quot;variable&quot; (&quot;type&quot;, &quot;1_product_id&quot;, &quot;2_project_id&quot;, &quot;3_pipeline_id&quot;, &quot;v_key&quot;, &quot;v_value&quot;) VALUES (&#x27;110&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;&#x27;, &#x27;1&#x27;, &#x27;1&#x27;);INSERT INTO &quot;public&quot;.&quot;variable&quot; (&quot;type&quot;, &quot;1_product_id&quot;, &quot;2_project_id&quot;, &quot;3_pipeline_id&quot;, &quot;v_key&quot;, &quot;v_value&quot;) VALUES (&#x27;100&#x27;, &#x27;1&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;1&#x27;, &#x27;1&#x27;); 查询 单查某一关联关系的值: SELECT * FROM &quot;variable&quot; WHERE &quot;type&quot;=b&#39;100&#39; AND &quot;1_product_id&quot; = &#39;1&#39; 单查与某个实体产生关系的所有值: SELECT * FROM &quot;variable&quot; WHERE &quot;type&quot;&amp;b&#39;100&#39;=b&#39;100&#39; AND &quot;1_product_id&quot; = &#39;1&#39; 单查与多个个实体产生关系的所有值: SELECT * FROM &quot;variable&quot; WHERE &quot;type&quot;&amp;b&#39;110&#39;=b&#39;110&#39; AND &quot;1_product_id&quot; = &#39;1&#39; AND &quot;2_project_id&quot; = &#39;1&#39; 扩展方式如果之后出现第四个实体4_tag，也需要与前几个字段建立关联关系，那么只需要简单扩展type字段的长度就可以了，当然也要同时变更下查询的SQL。需要注意的是，类型为bit的字段长度是不可变的，无论是增加长度还是缩减长度都需要现将字段类型改为varbit后再改回bit，例如bit(3)-&gt;varbit(5)-&gt;bit(5)。此时，字段长度增加后原数据都将向左移并补0，虽然上其数据值会增大，但是并不影响我们对关联关系的查询。"},{"title":"PostgreSql bit varying","path":"PostgreSql_bit_varying/","text":"PostgreSql bit varying应用场景 存储和可视化位掩码 参考 Bit String Types Bit String Functions and Operators 是动态长度的bit，以可读二进制数的方式展示 1SELECT B&#x27;10001&#x27; as num； num 10001 运算 &amp;位与运算 |位或运算 #异或运算 ~非运算 &lt;&lt;位左移 &gt;&gt;位右移 ||位拼接 12345678SELECT B&#x27;10001&#x27; &amp; B&#x27;01101&#x27; as &quot;and&quot;, B&#x27;10001&#x27; | B&#x27;01101&#x27; as &quot;or&quot;, B&#x27;10001&#x27; # B&#x27;01101&#x27; as &quot;eor &quot;, ~B&#x27;10001&#x27; as &quot;not&quot;, B&#x27;11111&#x27; &gt;&gt; 2 as &quot;shiftL&quot;, B&#x27;11111&#x27; &lt;&lt; 2 as &quot;shiftR&quot;, B&#x27;101&#x27; || B&#x27;01&#x27; as &quot;cancat &quot;; and or eor not shiftL shiftR cancat 00001 11101 11100 01110 00111 11100 10101 转换1234567SELECT B&#x27;10001&#x27; as &quot;varbit&quot;, cast(B&#x27;10001&#x27; as bit(3)) as &quot;bit3&quot;, cast(B&#x27;10001&#x27; as bit(5)) as &quot;bit&quot;, cast(B&#x27;10001&#x27; as bit(7)) as &quot;bit7&quot;, cast(cast(B&#x27;10001&#x27; as bit(5)) as integer) as &quot;int&quot;, B&#x27;10001&#x27;::bit(5)::integer as &quot;intLambda&quot;; varbit bit3 bit bit7 int intLambda 10001 100 10001 1000100 17 17"},{"title":"常见软件Proxy配置合集","path":"常见软件Proxy配置合集/","text":"System APT Docker System12export HTTP_PROXY=http://localhost:1080export HTTPS_PROXY=http://localhost:1080 APT/etc/apt/apt.conf.d/proxy.conf 12Acquire::http::Proxy &quot;http://localhost:1080&quot;;Acquire::https::Proxy &quot;http://localhost:1080&quot;; Docker/etc/systemd/system/docker.service.d/http-proxy.conf 1234[Service]Environment=&quot;HTTP_PROXY=http://192.167.20.38:1080&quot;Environment=&quot;HTTPS_PROXY=http://192.167.20.38:1080&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1,192.168.0.0/16&quot;"},{"title":"Kubernetes集群中拉取镜像走代理","path":"Kubernetes集群中拉取镜像走代理/","text":"三种方式 systemd中配置docker进程环境变量 docker守护线程用户代理配置 配置全局环境变量（大概没效果） systemd中配置docker进程环境变量方式一 一般来说直接改/usr/lib/systemd/system/docker.service就行，在其中的[Service]块中加上环境变量 Environment=&quot;HTTP_PROXY=http://192.167.20.38:1080&quot; Environment=&quot;HTTPS_PROXY=http://192.167.20.38:1080&quot; 最后再重启docker就行 12[root@vmw253 ~]# systemctl daemon-reload[root@vmw253 ~]# systemctl restart docker 方式二 （稍微优雅一点） vim &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;http-proxy.conf 1234[Service]Environment=&quot;HTTP_PROXY=http://192.167.20.38:1080&quot;Environment=&quot;HTTPS_PROXY=http://192.167.20.38:1080&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1,*.myhuaweicloud.com,192.167.0.0/16,192.168.0.0/16&quot; 然后与方式一一样重启docker,两种方式没啥区别都是一样的 重启好之后随便测试下12345678[root@vmw253 ~]# docker pull k8s.gcr.io/pause:3.03.0: Pulling from pausea3ed95caeb02: Pull complete f11233434377: Pull complete Digest: sha256:0d093c962a6c2dd8bb8727b661e2b5f13e9df884af9945b4cc7088d9350cd3eeStatus: Downloaded newer image for k8s.gcr.io/pause:3.0k8s.gcr.io/pause:3.0"},{"title":"修复Ubuntu下ADB设备无权限的问题","path":"修复Ubuntu下ADB设备无权限的问题/","text":"修复ADB设备无权限的问题接手同事的项目，在服务器(生产)上装了点依赖，重启了下系统，使用ADB连接的所有设备全都断连了。慌得一比，输出大概是下面这个样子。 1234567891011121314data@data:~$ /home/data/.local/share/virtualenvs/script-schedule-exec-w4db_Qrl/lib/python3.10/site-packages/airtest/core/android/static/adb/linux/adb devicesList of devices attached7DK7ZLVG99999999 device8144d0f2 no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]9486e0be no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]9584d066 no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]9LIN4SSC99999999 no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]I7VSE6DIRWLZ6T5H no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]JTK5T19909001733 devicea48ab864 devicebf7ddca0 no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]e232d448 no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]ec30a657 unauthorizedef68a8c6 no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html] 查询资料后发现是udev权限配置的问题，进入/etc/udev/rules.d/目录后发现配置文件全部不见了（不知道为啥），于是去github上下载了个配置文件，塞到配置目录后，重启udev和ADB-server后恢复了大半。 剩下没恢复的是Oppo和Vivo手机，仍然提示无权限。经检查，是规则文件中缺少他们的配置，于是自己加上配置后再次重启服务，问题得到解决。 参考资料 snowdream&#x2F;51-android 在硬件设备上运行应用 获取原始设备制造商 (OEM) 驱动程序 下载规则文件并重启 12345678sudo curl --create-dirs -L -o /etc/udev/rules.d/51-android.rules https://raw.githubusercontent.com/snowdream/51-android/master/51-android.ruleswget https://raw.githubusercontent.com/snowdream/51-android/master/51-android.rulesmv ./51-android.rules /etc/udev/rules.d/51-android.rulessudo mv ./51-android.rules /etc/udev/rules.d/51-android.rulessudo chmod a+r /etc/udev/rules.d/51-android.rulessudo service udev restart/home/data/.local/share/virtualenvs/script-schedule-exec-w4db_Qrl/lib/python3.10/site-packages/airtest/core/android/static/adb/linux/adb kill-server/home/data/.local/share/virtualenvs/script-schedule-exec-w4db_Qrl/lib/python3.10/site-packages/airtest/core/android/static/adb/linux/adb devices 新增规则 12345--- /etc/udev/rules.d/51-android.rules SUBSYSTEM==&quot;usb&quot;, ATTR&#123;idVendor&#125;==&quot;12d1&quot;, ATTR&#123;idProduct&#125;==&quot;107e&quot;,MODE=&quot;0666&quot;, GROUP=&quot;plugdev&quot;SUBSYSTEM==&quot;usb&quot;, ATTR&#123;idVendor&#125;==&quot;18d1&quot;, ATTR&#123;idProduct&#125;==&quot;4ee7&quot;,MODE=&quot;0666&quot;, GROUP=&quot;plugdev&quot;SUBSYSTEM==&quot;usb&quot;, ATTR&#123;idVendor&#125;==&quot;2d95&quot;, ATTR&#123;idProduct&#125;==&quot;6003&quot;,MODE=&quot;0666&quot;, GROUP=&quot;plugdev&quot;SUBSYSTEM==&quot;usb&quot;, ATTR&#123;idVendor&#125;==&quot;22d9&quot;, ATTR&#123;idProduct&#125;==&quot;2774&quot;,MODE=&quot;0666&quot;, GROUP=&quot;plugdev&quot; 修好了 12345678910111213141516data@data:~/workspace$ /home/data/.local/share/virtualenvs/script-schedule-exec-w4db_Qrl/lib/python3.10/site-packages/airtest/core/android/static/adb/linux/adb devicesList of devices attached(这个不知道咋回事，id重复就算了，还在爆无权限，但是能用)↓↓↓↓32615022 no permissions (user in plugdev group; are your udev rules wrong?); see [http://developer.android.com/tools/device.html]32615022 device7DK7ZLVG99999999 device8144d0f2 device9486e0be device9LIN4SSC99999999 deviceI7VSE6DIRWLZ6T5H deviceJTK5T19909001733 devicea48ab864 devicebf7ddca0 devicee232d448 deviceec30a657 deviceef68a8c6 device"},{"title":"使用JDBC操作Postgre时jsonb操作符被识别为参数的问题","path":"使用JDBC操作Postgre时jsonb操作符被识别为参数的问题/","text":"使用JDBC操作Postgre时jsonb操作符被识别为参数的问题一句话解决方式把sql中的?替换为??，就能解决 原SQL 12-- 可以在pgClient中正常执行SELECT * FROM project WHERE (tags ?&amp; array[&#x27;Sonar&#x27;]) 现SQL 12-- 可以通过org.postgresql.Driver正常执行SELECT * FROM project WHERE (tags ??&amp; array[&#x27;Sonar&#x27;]) 相关环境版本 org.postgresql.postgresql:42.3.4 报错的代码123456789101112131415@Overridepublic List&lt;Project&gt; listByQuery(ProjectQuery query) &#123; // json查询 if (CollectionUtils.isNotEmpty(tagContains)) &#123; var tagContainsArray = tagContains.toArray(); var placeHolder = IntStream.range(0, tagContains.size()).boxed().map(s -&gt; &quot;&#123;&quot; + s + &quot;&#125;&quot;) .collect(Collectors.joining(&quot;,&quot;, &quot;tags ?&amp; array[&quot;, &quot;]&quot;)); if (queryWrapper.nonEmptyOfWhere()) &#123; queryWrapper.apply(&quot;AND &quot; + placeHolder, tagContainsArray); &#125; else &#123; queryWrapper.apply(placeHolder, tagContainsArray); &#125; &#125; return baseMapper.selectList(queryWrapper); // &lt;= 此行报错&#125; 特征日志1234567891011121314151617181920212223242526272829303132332022-08-26 14:04:17.666 [TID:SLT-1563036635401490432] [ERROR] ller.GlobalExceptionController[70]- 出现未知异常:### Error querying database. Cause: org.postgresql.util.PSQLException: 未设定参数值 2 的内容。### The error may exist in com/kailinjt/middleware/beam/mapper/ProjectMapper.java (best guess)### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: SELECT id,key,display_name,description,product_id,technical_manager_id,gitlab_project_id,development_language,tags,create_time,update_time,create_user_id,update_user_id FROM project WHERE (tags ?&amp; array[?])### Cause: org.postgresql.util.PSQLException: 未设定参数值 2 的内容。; 未设定参数值 2 的内容。; nested exception is org.postgresql.util.PSQLException: 未设定参数值 2 的内容。org.springframework.dao.DataIntegrityViolationException: ### Error querying database. Cause: org.postgresql.util.PSQLException: 未设定参数值 2 的内容。### The error may exist in com/kailinjt/middleware/beam/mapper/ProjectMapper.java (best guess)### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: SELECT id,key,display_name,description,product_id,technical_manager_id,gitlab_project_id,development_language,tags,create_time,update_time,create_user_id,update_user_id FROM project WHERE (tags ?&amp; array[?])### Cause: org.postgresql.util.PSQLException: 未设定参数值 2 的内容。; 未设定参数值 2 的内容。; nested exception is org.postgresql.util.PSQLException: 未设定参数值 2 的内容。 at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104) ~[spring-jdbc-5.3.14.jar:5.3.14] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70) ~[spring-jdbc-5.3.14.jar:5.3.14] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:79) ~[spring-jdbc-5.3.14.jar:5.3.14] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:79) ~[spring-jdbc-5.3.14.jar:5.3.14] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91) ~[mybatis-spring-2.0.6.jar:2.0.6] &lt;!-- 下面这行堆栈是框架代码的错误源，上面的堆栈是在抛出和翻译这个错误 --&gt; at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) ~[mybatis-spring-2.0.6.jar:2.0.6] at jdk.proxy2.$Proxy139.selectList(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:224) ~[mybatis-spring-2.0.6.jar:2.0.6] at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForMany(MybatisMapperMethod.java:166) ~[mybatis-plus-core-3.4.3.4.jar:3.4.3.4] at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:77) ~[mybatis-plus-core-3.4.3.4.jar:3.4.3.4] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) ~[mybatis-plus-core-3.4.3.4.jar:3.4.3.4] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) ~[mybatis-plus-core-3.4.3.4.jar:3.4.3.4] at jdk.proxy2.$Proxy165.selectList(Unknown Source) ~[?:?] &lt;!-- 下面这行堆栈是业务代码错误源，上面的堆栈是在框架中处理的 --&gt; at com.kailinjt.middleware.beam.service.impl.ProjectServiceImpl.listByQuery(ProjectServiceImpl.java:103) ~[classes/:?] &lt;!-- 以下堆栈业务无关，因此略掉... --&gt; 源码跟踪 由日志可知，这段SQL中有两个参数需要填充，但我们只传入了一个参数导致报错 1Cause: org.postgresql.util.PSQLException: 未设定参数值 2 的内容。 打开问题SQL发现这个SQL中的确只有一个参数，猜测是PG的jsonb操作符?&amp;中的?被错误的识别为了参数，基于此，反向查找参数来源。 1SELECT id,key,display_name,description,product_id,technical_manager_id,gitlab_project_id,development_language,tags,create_time,update_time,create_user_id,update_user_id FROM project WHERE (tags ?&amp; array[?]) 根据堆栈反向查找错误源org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) ~[mybatis-spring-2.0.6.jar:2.0.6] 123456789101112131415161718192021222324252627282930313233private class SqlSessionInterceptor implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; SqlSession sqlSession = getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; Object result = method.invoke(sqlSession, args); // &lt;= 实际报错的是这行 if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; // force commit even on non-dirty sessions because some databases require // a commit/rollback before calling close() sqlSession.commit(true); &#125; return result; &#125; catch (Throwable t) &#123; Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) &#123; // release the connection to avoid a deadlock if the translator is no loaded. See issue #22 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator .translateExceptionIfPossible((PersistenceException) unwrapped); // &lt;= 报错的是这行 if (translated != null) &#123; unwrapped = translated; &#125; &#125; throw unwrapped; &#125; finally &#123; if (sqlSession != null) &#123; closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; &#125;&#125; 到第三步这里发现已经在mybatis和jdbcDriver里了，但是还看不出问题，因为看漏了一个Caused by1234567891011121314151617181920212223242526272829303132 Caused by: org.postgresql.util.PSQLException: 未设定参数值 2 的内容。at org.postgresql.core.v3.SimpleParameterList.checkAllParametersSet(SimpleParameterList.java:284) ~[postgresql-42.3.4.jar:42.3.4]at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:339) ~[postgresql-42.3.4.jar:42.3.4]at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:490) ~[postgresql-42.3.4.jar:42.3.4]at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:408) ~[postgresql-42.3.4.jar:42.3.4]at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:167) ~[postgresql-42.3.4.jar:42.3.4]at org.postgresql.jdbc.PgPreparedStatement.execute(PgPreparedStatement.java:156) ~[postgresql-42.3.4.jar:42.3.4]at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:497) ~[druid-1.2.8.jar:1.2.8]at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:64) ~[mybatis-3.5.7.jar:3.5.7]at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) ~[mybatis-3.5.7.jar:3.5.7]at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]at java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) ~[mybatis-3.5.7.jar:3.5.7]at jdk.proxy2.$Proxy222.query(Unknown Source) ~[?:?]at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) ~[mybatis-3.5.7.jar:3.5.7]at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:325) ~[mybatis-3.5.7.jar:3.5.7]at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) ~[mybatis-3.5.7.jar:3.5.7]at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) ~[mybatis-3.5.7.jar:3.5.7]at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:81) ~[mybatis-plus-extension-3.4.3.4.jar:3.4.3.4]at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) ~[mybatis-3.5.7.jar:3.5.7]at jdk.proxy2.$Proxy221.query(Unknown Source) ~[?:?]at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:151) ~[mybatis-3.5.7.jar:3.5.7]at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:145) ~[mybatis-3.5.7.jar:3.5.7]at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) ~[mybatis-3.5.7.jar:3.5.7]at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]at java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ~[mybatis-spring-2.0.6.jar:2.0.6]... 128 more 导航到驱动中的异常点org.postgresql.core.v3.SimpleParameterList.checkAllParametersSet(SimpleParameterList.java:284) ~[postgresql-42.3.4.jar:42.3.4]，发现根本原因果然是参数列表paramValues预期两个值，实际只有一个值导致的123456789@Overridepublic void checkAllParametersSet() throws SQLException &#123; for (int i = 0; i &lt; paramTypes.length; ++i) &#123; if (direction(i) != OUT &amp;&amp; paramValues[i] == null) &#123; throw new PSQLException(GT.tr(&quot;No value specified for parameter &#123;0&#125;.&quot;, i + 1), PSQLState.INVALID_PARAMETER_VALUE); &#125; &#125;&#125; 反向查找类变量paramValues是何时被赋值的: org.postgresql.core.v3.SimpleParameterList#SimpleParameterList[48]构造方法传入 org.postgresql.core.v3.SimpleQuery#createParameterList[52] 由getBindCount()计算得到 由类变量nativeQuery.bindPositions的长度乘以批处理数getBatchSize()得到 1234public final int getBindCount() &#123; return nativeQuery.bindPositions.length * getBatchSize();&#125; 反向查找类变量nativeQuery.bindPositions是何时被赋值的: org.postgresql.core.NativeQuery#NativeQuery(java.lang.String, int[], boolean, org.postgresql.core.SqlCommand)[36-37]构造方法传入 这个构造使用的方式太多了，在这行打个断点，启动应用后执行SQL触发断点，动态抛出一个异常获取堆栈: 1234567891011java.lang.Exception at org.postgresql.core.NativeQuery.&lt;init&gt;(NativeQuery.java:36) &lt;!-- 得到真实的使用位置 --&gt; at org.postgresql.core.Parser.parseJdbcSql(Parser.java:295) at org.postgresql.core.CachedQueryCreateAction.create(CachedQueryCreateAction.java:65) at org.postgresql.core.CachedQueryCreateAction.create(CachedQueryCreateAction.java:19) at org.postgresql.util.LruCache.borrow(LruCache.java:123) at org.postgresql.core.QueryExecutorBase.borrowQuery(QueryExecutorBase.java:296) at org.postgresql.jdbc.PgConnection.borrowQuery(PgConnection.java:172) at org.postgresql.jdbc.PgPreparedStatement.&lt;init&gt;(PgPreparedStatement.java:88) &lt;!-- 以下堆栈略 --&gt; 发现原参数是bindPositions的包装，转而追踪参数bindPositions: 12345NativeQuery lastQuery = new NativeQuery(nativeSql.toString(), toIntArray(bindPositions), !splitStatements, // &lt;= 就是这个toInArray包装 SqlCommand.createStatementTypeInfo(currentCommandType, isBatchedReWriteConfigured, valuesBraceOpenPosition, valuesBraceClosePosition, isReturningPresent, (nativeQueries == null ? 0 : nativeQueries.size()))); 追踪到org.postgresql.core.Parser#parseJdbcSqlSQL解析器中,读取到SQL中的?时的处理方式: 1234567891011121314151617181920212223case &#x27;?&#x27;: nativeSql.append(aChars, fragmentStart, i - fragmentStart); // 有连续两个?的时候，只向sql中拼接一个?，不计入bindPositions中 if (i + 1 &lt; aChars.length &amp;&amp; aChars[i + 1] == &#x27;?&#x27;) /* replace ?? with ? */ &#123; nativeSql.append(&#x27;?&#x27;); i++; // make sure the coming ? is not treated as a bind &#125; else &#123; // 只有一个?的时候，检查是否解析参数 if (!withParameters) &#123; // 不解析参数 nativeSql.append(&#x27;?&#x27;); &#125; else &#123; // 解析参数 if (bindPositions == null) &#123; bindPositions = new ArrayList&lt;Integer&gt;(); &#125; bindPositions.add(nativeSql.length()); int bindIndex = bindPositions.size(); nativeSql.append(NativeQuery.bindName(bindIndex)); &#125; &#125; fragmentStart = i + 1; break; 把sql中的?替换为??，问题成功解决。"},{"title":"Linux下的简单网络管理","path":"Linux下的简单网络管理/","text":"使用Netplan管理网络配置相关资料 Netplan文档地址 Netplan配置地址: /etc/netplan/xxxx.yaml NetworkManager文档地址 NetworkManager配置地址: /etc/NetworkManager/NetworkManager.conf 步骤 修改配置 应用网络策略sudo netlpan apply 12345678910111213141516171819# This is the network config written by &#x27;subiquity&#x27;network:version: 2# 可选值 NetworkManager | networkdrenderer: NetworkManagerethernets: eno1: addresses: - 192.167.20.211/24 gateway4: 192.167.20.1 nameservers: addresses: - 192.167.20.1 - 114.114.114.114 - 1.1.1.1 search: [] eno2: dhcp4: true 使用sudo nmtui微调网络，如果nmtui中看不到接口，则检查配置后使用sudo systemctl reload NetworkManager重启服务即可 静态配置(旧版Ubuntu) 静态ip配置: /etc/network/interfaces 静态dns配置: /etc/resolv.conf"},{"title":"解决Springdoc-OAS3中Schema重复的问题","path":"解决Springdoc-OAS3中Schema重复的问题/","text":"在使用springdoc-openapi时，如果项目中存在多个SimpleName一致的Class，那在Schema描述中将会依照解析的先后顺序互相覆盖，从而导致Api文档的描述与预期不一致。 相似问题 Duplicate class names in different packages get squashed in ControllerDocumentation 解决方案 启用springdoc.use-fqn属性，所有的类将解析为全限定名 重写TypeNameResolver，自定义解析规则 重写TypeNameResolver需要注意的是，父类中useFqn被限定为private，在子类中无法获取。因此重写的逻辑（除super.getNameOfClass(cls)外）无法对开启useFqn的情况做出适配。 1234567891011121314151617/** * 用于自定义Schema生成逻辑 以区分不同包下的同名Schema */public class CustomOAS3TypeNameResolver extends TypeNameResolver &#123; @Override protected String getNameOfClass(Class&lt;?&gt; cls) &#123; var packageName = cls.getPackageName(); if (packageName.contains(&quot;xxxxxx&quot;)) &#123; return cls.getSimpleName(); &#125; else if (packageName.contains(&quot;org.gitlab4j&quot;)) &#123; return &quot;Gitlab&quot; + cls.getSimpleName(); &#125; return super.getNameOfClass(cls); &#125;&#125; 替换掉原本的TypeNameResolver 原本的TypeNameResolver是个私有静态单例，上面还打了final标记，看起来是没有替换原本变量的可能了。 往上一层走到ModelResolver类中，这个类提供了两个构造，其中一个支持传入TypeNameResolver参数，可以从这里入手覆盖。 ModelResolver是被ModelResolvers初始化的，虽然ModelConverters也是个私有静态单例改不掉他，但他本质是个对List&lt;ModelConverter&gt;的包装类，提供了操作其中converters的方法，所以我们可以通过操作内部的数组来放入自定义的TypeNameResolver。 由于ModelConverters也是静态单例，只要在Spring调用它解析Model之前替换调原本的TypeNameResolver就行了，因此可以直接怼到启动类中。 12345678910111213141516171819@SpringBootApplicationpublic class BeamApplication &#123; public static void main(String[] args) &#123; customOAS3TypeConverter(); SpringApplication.run(BeamApplication.class, args); &#125; /** * 自定义OAS3类型转换器 */ private static void customOAS3TypeConverter() &#123; var instance = ModelConverters.getInstance(); var converter = instance.getConverters().get(0); instance.removeConverter(converter); instance.addConverter(new ModelResolver(Json.mapper(), new CustomOAS3TypeNameResolver())); &#125;&#125; 重启项目后，打开openapi文档。相同SimpleName的Schema已经区分来了。"},{"title":"由XXL-admin日志序列化异常导致的事故","path":"由XXL-admin日志序列化异常导致的事故/","text":"原因分析 客户端回调日志序列化出现问题 服务端收到callback后反序列化失败抛出500 客户端收到500错误码无限重试 由于配置错误多个客户端扫描了NFS上同一个日志目录 多个客户端重试同一条日志，错误被放大 服务端错误日志中打印了出入参，由于大量客户端重发callback，日志狂刷 xxl服务端日志滚动规则仅仅配置了日期滚动，未配置按大小滚动，错误兜底失败 服务器用于存储日志的磁盘爆满，所有服务都爆炸啦！！（高兴 关键堆栈信息，DEBUG详情之后复现时补充1234com.xxl.job.core.thread.TriggerCallbackThread#startcom.xxl.job.core.thread.TriggerCallbackThread#retryFailCallbackFilecom.xxl.job.core.thread.TriggerCallbackThread#doCallbackcom.xxl.job.core.thread.TriggerCallbackThread#doCallback[166] 反序列化失败的callback日志示例 xxl-job-callback-1660189083244.log 服务器反序列化造成的错误日志123456789101112131415Caused by: com.fasterxml.jackson.core.JsonParseException: Unrecognized character escape &#x27;I&#x27; (code 73) at [Source: [&#123;&quot;logId&quot;:457389,&quot;logDateTim&quot;:1659750000001,&quot;executeResult&quot;:&quot;**此处内容为上述callback.log内容**&quot;,&quot;content&quot;:null&#125;&#125;]; line: 1, column: 898] at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1702) at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:558) at com.fasterxml.jackson.core.base.ParserMinimalBase._handleUnrecognizedCharacterEscape(ParserMinimalBase.java:535) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._decodeEscaped(ReaderBasedJsonParser.java:2536) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._finishString2(ReaderBasedJsonParser.java:2057) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._finishString(ReaderBasedJsonParser.java:2030) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.getText(ReaderBasedJsonParser.java:276) at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:36) at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11) at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:504) at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:104) at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:276) ... 78 common frames omitted"},{"title":"为Oracle实例挂载块存储","path":"为Oracle实例挂载块存储/","text":"所谓块存储说人话就是云硬盘，购买块存储简单理解就是买了块已经做好scsi的硬盘，买块硬盘之后插到服务器上就能用了。大概流程就是下面这种： 1购买块存储 -&gt; 附加到实例 -&gt; 分区 -&gt; 挂载 如果需要多个实例共享一个空间的话则有多种方式 将块存储同时挂载到多个实例，再将存储中分区的文件系统格式化为共享型存储系统 将块存储挂载到单个实例上，再将使用NFS共享块存储 购买块存储准备好钱直接买就是了，免费账户有50G的免费空间，做做实验啥的也够了。 附加到实例买好了块存储，点进详情就可以附加到实例。这里需要注意下，如果多个实例想挂载同一个块存储，那需要选择读/写 - 可共享选项。![附加到实例](cover: https://dreamccc-note.oss-cn-chengdu.aliyuncs.com/note/images/posts/为Oracle实例挂载块存储/attach2instance.png) 参考资料 xfs-vs-ext4 service-iscsi choosing-between-network-and-shared-storage-file-systems_assembly_overview-of-available-file-systems ch-ext4 Ramble_about_distributed_storage_schemes.pdf"},{"title":"搭建Maven脚手架时一些并不太常见的问题","path":"搭建Maven脚手架时一些并不太常见的问题/","text":"使用脚手架生成的pom.xml中含有大量空白行片段如下图，生成的xml含有大量空白行 12345678910111213141516171819202122232425262728293031323334353637383940&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.79&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;31.0.1-jre&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-ext&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!-- endregion --&gt; &lt;/dependencies&gt; 参考资料 Remove dom4j library Resulting root pom.xml from archetype generation has additional newlines with JDK11 Multi-modules Archetypes’ Root POM file contains empty lines in Java 11 解决方案这是maven-archetype-plugin插件的BUG，起因是maven-archetype-plugin:3.1.1使用Java XML API替换了dom4j用以生成xml，此行为导致不同的Java版本将会影响最终xml的生成结果。 最终解决方案就是换用maven-archetype-plugin:3.1.0及以下版本，或者使用Java8. 在项目中添加.gitignore文件脚手架结构如下图所示，其中以.开头的隐藏文件均为包含在输出目录中 123456789101112131415161718192021xxx-archetype|- .idea|- src| |- main| |- resources| |- archetype-resources| | |- __rootArtifactId__-common| | |- __rootArtifactId__-data| | |- __rootArtifactId__-proxy| | |- __rootArtifactId__-service| | |- __rootArtifactId__-web| | |- .editorconfig| | |- .gitignore| | |- .gitlab-ci.yml| | |- Dockerfile| | |- lombok.config| | |- pom.xml| |- META-INF| |- maven| |- archetype-metadata.xml|- pom.xml 解决方式： 修改pom.xml升级maven-archetype-plugin到3.2.1版本，并设置变量useDefaultExcludes=false 12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-archetype-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt; &lt;configuration&gt; &lt;useDefaultExcludes&gt;false&lt;/useDefaultExcludes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 修改pom.xml升级maven-resources-plugin到3.2.0版本，并设置变量addDefaultExcludes=false 12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;configuration&gt; &lt;addDefaultExcludes&gt;false&lt;/addDefaultExcludes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 在archetype-metadata.xml中添加需要包含的文件 123456789101112&lt;fileSets&gt; &lt;fileSet filtered=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory/&gt; &lt;includes&gt; &lt;include&gt;.editorconfig&lt;/include&gt; &lt;include&gt;.gitignore&lt;/include&gt; &lt;include&gt;Dockerfile&lt;/include&gt; &lt;include&gt;lombok.config&lt;/include&gt; &lt;include&gt;.gitlab-ci.yml&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt;&lt;/fileSets&gt; 在archetype-metadata.xml中启用代码提示 (适用于所有XML)按照官方文档将namespace更新为1.1.0版本，并在idea中将光标指向xmlns链接点击获取外部资源即可。 123456&lt;archetype-descriptor xmlns=&quot;https://maven.apache.org/plugins/maven-archetype-plugin/archetype-descriptor/1.1.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;https://maven.apache.org/plugins/maven-archetype-plugin/archetype-descriptor/1.1.0 http://maven.apache.org/xsd/archetype-descriptor-1.1.0.xsd&quot; name=&quot;xxxxx-archetype&quot; partial=&quot;false&quot;&gt;&lt;/archetype-descriptor&gt;"},{"title":"文件观察者数量超过系统限制","path":"deepin下系统监控文件数量超过限制/","text":"症状1在系统文件管理器中新建文件时不会自动刷新。 症状2启动Angular项目报了如下错误： 1234Watchpack Error (watcher): Error: ENOSPC: System limit for number of file watchers reached, watch &#x27;/home/daizc/IdeaProjects/beam/beam-frontend/src/main/angular/node_modules/@webcomponents/webcomponentsjs&#x27;Watchpack Error (watcher): Error: ENOSPC: System limit for number of file watchers reached, watch &#x27;/home/daizc/IdeaProjects/beam/beam-frontend/src/main/angular/node_modules/@webcomponents&#x27;Watchpack Error (watcher): Error: ENOSPC: System limit for number of file watchers reached, watch &#x27;/home/daizc/IdeaProjects/beam/beam-frontend/src/main/angular/node_modules/@types/trusted-types&#x27;Watchpack Error (watcher): Error: ENOSPC: System limit for number of file watchers reached, watch &#x27;/home/daizc/IdeaProjects/beam/beam-frontend/src/main/angular/node_modules/@types&#x27; 解决方案:AReact Native Error: ENOSPC: System limit for number of file watchers reached 经验证，重启后会失效 12sudo sysctl fs.inotify.max_user_watches=524288 # 我自己设置的是131072sudo sysctl -p 解决方案:BInotify 监视限制 (Linux) 将以下行添加到&#x2F;etc&#x2F;sysctl.conf文件或目录下的新*.conf文件（例如idea.conf）&#x2F;etc&#x2F;sysctl.d&#x2F;: fs.inotify.max_user_watches = 524288 然后运行此命令以应用更改： sudo sysctl -p --system 系统环境: OS: Deepin 20.6 apricot Kernel: x86_64 Linux 5.10.101-amd64-desktop"},{"title":"在K8s中部署projector-idea-u","path":"在K8s中部署projector-idea-u/","text":"编写部署文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# 提供NodePort供外部访问apiVersion: v1kind: Servicemetadata: name: idea-u-daizc-nodeport namespace: default labels: app.kubernetes.io/name: idea-u-daizcspec: type: NodePort ports: - port: 8887 targetPort: 8887 nodePort: 31887 selector: app.kubernetes.io/name: idea-u-daizc---# 提供ClusterIP供内部解析apiVersion: v1kind: Servicemetadata: name: idea-u-daizc namespace: default labels: app.kubernetes.io/name: idea-u-daizcspec: type: ClusterIP ports: - port: 8887 protocol: TCP name: http selector: app.kubernetes.io/name: idea-u-daizc---# 使用有状态副本集部署apiVersion: apps/v1kind: StatefulSetmetadata: name: idea-u-daizc namespace: default labels: app.kubernetes.io/name: idea-u-daizcspec: selector: matchLabels: app.kubernetes.io/name: idea-u-daizc serviceName: &quot;idea-u-daizc&quot; replicas: 1 # 默认值是 1 minReadySeconds: 0 # 默认值是 0 template: metadata: labels: app.kubernetes.io/name: idea-u-daizc # 必须匹配 .spec.selector.matchLabels spec: terminationGracePeriodSeconds: 60 containers: - name: idea-u-daizc image: jetbrains/projector-idea-u:2021.3-projector-v1.8.1 ports: - containerPort: 8887 protocol: TCP name: http volumeMounts: - mountPath: /home/projector-user name: idea-u-daizc-volume volumes: - name: idea-u-daizc-volume persistentVolumeClaim: claimName: idea-u-daizc-pvc---# 使用PVC声明需要的持久化存储空间apiVersion: v1kind: PersistentVolumeClaimmetadata: name: idea-u-daizc-pvcspec: storageClassName: idea-u-daizc-pv-storage-class-name # 需要与PVC的对应，否则无法成功申领下面的PV accessModes: - ReadWriteMany resources: requests: storage: 10Gi---# 为PVC手动创建PV卷apiVersion: v1kind: PersistentVolumemetadata: name: idea-u-daizc-pvspec: # 访问模式 # https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes # ReadWriteOnce 卷可以被一个节点以读写方式挂载。 ReadWriteOnce 访问模式也允许运行在同一节点上的多个 Pod 访问卷。 # ReadOnlyMany 卷可以被多个节点以只读方式挂载。 # ReadWriteMany 卷可以被多个节点以读写方式挂载。 # ReadWriteOncePod 卷可以被单个 Pod 以读写方式挂载。 如果你想确保整个集群中只有一个 Pod 可以读取或写入该 PVC， 请使用 # ReadWriteOncePod 访问模式。这只支持 CSI 卷以及需要 Kubernetes 1.22 以上版本。 accessModes: - ReadWriteMany capacity: storage: 10Gi # 使用NFS作为PV提供者 nfs: # 这个path需要在NFS处配置 path: /opt/nfs/idea-u-daizc-pv server: 192.168.21.24 storageClassName: idea-u-daizc-pv-storage-class-name # PV回收策略 # https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/#reclaim-policy # Retain 手动回收 # Recycle 基本擦除 (rm -rf /thevolume/*) # Delete 诸如 AWS EBS、GCE PD、Azure Disk 或 OpenStack Cinder 卷这类关联存储资产也被删除 persistentVolumeReclaimPolicy: Retain volumeMode: Filesystem 修改NFS配置 在部署PV时写死的nfs路径需要真实存在，如果不存在需要新建 在/etc/exports中新增导出项 1234# 集群地址放行 /opt/nfs/idea-u-daizc-pv 192.168.21.0/24(rw,sync,all_squash)# 本地地址放行/opt/nfs/idea-u-daizc-pv 192.167.20.38/32(rw,sync,all_squash) 需要注意NFS用户权限映射相关配置（使用man export查看） root_squash，当NFS客户端以root用户身份访问时，映射为NFS服务器的nfsnobody用户 no_root_squash，当NFS客户端以root身份访问时，映射为NFS服务器的root用户，也就是要为超级用户保留权限。这个选项会留下严重的安全隐患，一般不建议采用 all_squash，无论NFS客户端以哪种用户身份访问，均映射为NFS服务器的nfsnobody用户其中默认值是root_squash，即当客户端以root用户的身份访问NFS共享时，在服务器端会自动被映射为匿名账号nfsnobody 使用exportfs -rav命令重载NFS服务。 *如果挂载成功后pod内报权限异常就把整个nfs的挂载目录权限改成777 开始部署 使用kubectl apply -f xxx部署上面的yml 观察PV、PVC是否为绑定状态(STATUS为Bound) 123456daizc@KAILIN-DAIZC:/mnt/d/deployment$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEidea-u-daizc-pvc Bound idea-u-daizc-pv 10Gi RWX idea-u-daizc-pv-storage-class-name 3d19hdaizc@KAILIN-DAIZC:/mnt/d/deployment$ kubectl -n ops get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEidea-u-daizc-pv 10Gi RWX Retain Bound default/idea-u-daizc-pvc idea-u-daizc-pv-storage-class-name 3d19h 观察StatefulSet和Pod是否启动成功123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160daizc@KAILIN-DAIZC:/mnt/d/deployment$ kubectl describe statefulsets.apps idea-u-daizcName: idea-u-daizcNamespace: defaultCreationTimestamp: Thu, 02 Jun 2022 12:59:00 +0800Selector: app.kubernetes.io/name=idea-u-daizcLabels: app.kubernetes.io/name=idea-u-daizcAnnotations: &lt;none&gt;Replicas: 1 desired | 1 totalUpdate Strategy: RollingUpdate Partition: 0Pods Status: 1 Running / 0 Waiting / 0 Succeeded / 0 FailedPod Template: Labels: app.kubernetes.io/name=idea-u-daizc Containers: idea-u-daizc: Image: jetbrains/projector-idea-u:2021.3-projector-v1.8.1 Port: 8887/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: /home/projector-user from idea-u-daizc-volume (rw) Volumes: idea-u-daizc-volume: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: idea-u-daizc-pvc ReadOnly: falseVolume Claims: &lt;none&gt;Events: &lt;none&gt;daizc@KAILIN-DAIZC:/mnt/d/deployment$ kubectl get pod idea-u-daizc-0 -oyamlapiVersion: v1kind: Podmetadata: annotations: cni.projectcalico.org/containerID: bbfe0e4675cece177bd362cd3955995b5b0bc3c4ef55939fbbf845b10fa29505 cni.projectcalico.org/podIP: 10.233.97.107/32 cni.projectcalico.org/podIPs: 10.233.97.107/32 creationTimestamp: &quot;2022-06-02T06:38:10Z&quot; generateName: idea-u-daizc- labels: app.kubernetes.io/name: idea-u-daizc controller-revision-hash: idea-u-daizc-5578c99bf7 statefulset.kubernetes.io/pod-name: idea-u-daizc-0 name: idea-u-daizc-0 namespace: default ownerReferences: - apiVersion: apps/v1 blockOwnerDeletion: true controller: true kind: StatefulSet name: idea-u-daizc uid: 1e13554f-a842-48dc-ab71-f01114c8cb3d resourceVersion: &quot;21106533&quot; selfLink: /api/v1/namespaces/default/pods/idea-u-daizc-0 uid: fa9a121d-278c-477b-bd6c-290401a49840spec: containers: - image: jetbrains/projector-idea-u:2021.3-projector-v1.8.1 imagePullPolicy: IfNotPresent name: idea-u-daizc ports: - containerPort: 8887 name: http protocol: TCP resources: &#123;&#125; terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /home/projector-user name: idea-u-daizc-volume - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-dtdp9 readOnly: true dnsPolicy: ClusterFirst enableServiceLinks: true hostname: idea-u-daizc-0 nodeName: node9 preemptionPolicy: PreemptLowerPriority priority: 0 restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; serviceAccount: default serviceAccountName: default subdomain: idea-u-daizc terminationGracePeriodSeconds: 60 tolerations: - effect: NoExecute key: node.kubernetes.io/not-ready operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 volumes: - name: idea-u-daizc-volume persistentVolumeClaim: claimName: idea-u-daizc-pvc - name: kube-api-access-dtdp9 projected: defaultMode: 420 sources: - serviceAccountToken: expirationSeconds: 3607 path: token - configMap: items: - key: ca.crt path: ca.crt name: kube-root-ca.crt - downwardAPI: items: - fieldRef: apiVersion: v1 fieldPath: metadata.namespace path: namespacestatus: conditions: - lastProbeTime: null lastTransitionTime: &quot;2022-06-02T06:38:11Z&quot; status: &quot;True&quot; type: Initialized - lastProbeTime: null lastTransitionTime: &quot;2022-06-02T07:04:13Z&quot; status: &quot;True&quot; type: Ready - lastProbeTime: null lastTransitionTime: &quot;2022-06-02T07:04:13Z&quot; status: &quot;True&quot; type: ContainersReady - lastProbeTime: null lastTransitionTime: &quot;2022-06-02T06:38:11Z&quot; status: &quot;True&quot; type: PodScheduled containerStatuses: - containerID: containerd://d98a22a7534a147c240fb44d93d784090979e524e69a6f4195a908ee8f2609a6 image: docker.io/jetbrains/projector-idea-u:2021.3-projector-v1.8.1 imageID: docker.io/jetbrains/projector-idea-u@sha256:fab2a81caa691ecc92faa20c453e8e911b0cd216793a8d97c3dc2dce579b8424 lastState: terminated: containerID: containerd://c88b860653dac1f3e4680fb62fdefcd5fe73e210780078374d985da55b2cfd39 exitCode: 0 finishedAt: &quot;2022-06-02T07:04:11Z&quot; reason: Completed startedAt: &quot;2022-06-02T06:38:12Z&quot; name: idea-u-daizc ready: true restartCount: 1 started: true state: running: startedAt: &quot;2022-06-02T07:04:12Z&quot; hostIP: 192.168.21.89 phase: Running podIP: 10.233.97.107 podIPs: - ip: 10.233.97.107 qosClass: BestEffort startTime: &quot;2022-06-02T06:38:11Z&quot; 使用浏览器直接访问或者JetBrains Projector进行连接 使用Chrome连接时,会遇到各种权限问题 【建议】使用Projector连接，在拷贝内容时不会触发浏览器警告"},{"title":"研发编码规范","path":"研发编码规范-2022年4月13日/","text":"研发编码规范产品-应用关系描述 产品是进行缺陷管理、需求管理的最小单位 按照业务线作区分 应用是进行代码开发的最小单位 一个应用对应一个代码仓库 产品与应用为一对多的关系，即一个产品有多个应用。 产品具有以下基本属性 displayName 显示名称（中文名称，仅做显示之用） name 英文全称 perfix 前缀（5个字符以内） 应用具有以下基本属性 displayName 显示名称（中文名称，仅做显示之用） name 英文全称（默认为Maven工件Id） simpleName 简短名称（14个字符以内） 命名规则项目命名规则 Maven项目名：（由脚手架自动生成） 项目名(artifactId)统一使用小写，以中划线-作为分隔符 API模块的artifactId应该以-api结尾 应用模块如果与API包在同一个仓库中，则artifactId应以’-biz’结尾。 应用模块位于单独的代码仓库中，则artifactId无需添加后缀。 Java单体项目名规则： &lt;语言&gt;-&lt;业务名称&gt;-&lt;项目类型&gt; 语言 java php node 业务名称 auth product resource-center 项目类型 cloud boot 123456789单体项目java-xxxxx-cloudjava-xxxxx-cloud-api聚合项目ng-xxxxx |- ng-xxxxx-api |- ng-xxxxx-biz Maven GroupId必须满足以下正则表达式 ^com.kailin.* 类命名规则 功能 后缀 例子 备注 表名 - user_detail 表名仅做建议，根据业务可自行添加前缀后缀 复合实体 - UserDetail 简单CRUD场景下，用于代替领域对象、数据对象的功能无法替代DTO和VO 领域对象 Domian UserDetailDomain 胖实体，拥有业务上的方法，无法从数据库直接得到，简单CRUD无需领域对象&#x2F;复合实体的，可与DO混用 数据对象 DO UserDetailDO 从数据库中直接查询得到的对象，一般会类上存在ORM相关的注解简单CRUD场景下可用复合实体&#x2F;领域对象代替 数据传输对象 DTO UserDetailDTO 一般是放在Api包中提供出去 用与前端展示的POJO类 VO UserDetailVO - 数据库映射接口 Mapper UserMapper Mybatis用 数据库映射接口 Repository UserRepository JPA用 数据Service接口 IService UserDetailIService 使用MybatisPlus时，用于区分业务Service和数据Service 数据Service实现 IServiceImpl UserDetailIServiceImpl - Service接口 Service UserDetailService 真实提供业务的Service接口 Service实现 ServiceImpl UserDetailServiceImpl - web接口 Controller UserDetailController - web接口入参 Param UserDetailParam 执行特定业务时所需的入参 web接口查询复合参数 Query UserDetailQuery 【仅建议】执行特定查询时所用的查询参数 工具类 Utils DateUtils 一个工具类是一个工具集，因此用复数 自己编写工具类之前先看看项目内已引入工具能不能满足需求使用优先顺序为 commons.lang3 &gt; hutool &gt; spring &gt; 自己编写 常量类 Constants UserTypeConstants 一个常量类中含有多个常量，因此用复数 枚举类 Enum UserTypeEnum 枚举不是一个集合，而是一个类型定义， 数据访问层命名规则接口方法规范（参照JPA规范） 使用get、find、list、stream、update、save、delete作为前缀 使用By、OrderBy、GroupBy作为谓词 方法命名规则： &lt;前缀&gt;&lt;实体名or字段名&gt;&lt;谓词1&gt;&lt;字段名1&gt;&lt;谓词2&gt;&lt;字段名2&gt; 当查询结果为实体时，实体名可省略： 如getUserById()省略实体名为getById() 当查询结果为实体的派生对象时时，实体名可省略为后缀： 如getUserVOById()省略实体名为getVOById() 当查询结果为字段名或者特定对象时，不可省略 如getPasswordById()无法省略 如getLoginSlatAndPasswordById()无法省略 前缀规范 获取单个对象的方法用 get 做前缀时，返回T或者null。 如： UserDetailDO getUserDetailById(); 【推荐】获取单个对象的方法用 find 做前缀时，返回Optional&lt;T&gt;。 如： Optional&lt;UserDetailDO&gt; findUserDetailByName()。 如： Optional&lt;UserDetailDO&gt; findUserDetailByName()。 获取多个对象的方法用 list 做前缀时，实体采用复数结尾，返回&lt;? extend Collection&gt;&lt;T&gt;即Collection的子类 如： List&lt;UserDetailDO&gt; list()(省略对象名)。 如： List&lt;UserDetailDO&gt; listUserDetails()。 如： Set&lt;UserDetailDO&gt; listUserDetailsByCreateTime(Date createTime)。 如： Queue&lt;UserDetailDO&gt; listUserDetailsByAge(Long age)。 【推荐】获取多个对象的方法用 stream 做前缀时，实体采用复数结尾，返回Stream&lt;T&gt; 如： Stream&lt;UserDetail&gt; stream()(省略对象名)。 如： Stream&lt;UserDetail&gt; streamUserDetails()。 分页查询对象的方法用 page 做前缀，复数结尾。 如： Page&lt;UserDetail&gt; pageUserDetails(PageParam param)。 统计总数的方法用 count 做前缀。 如： Long countByAge(Long age)。 插入的方法用 save 做前缀。 返回保存的实体. 如： UserDetailDO save(UserDetailDO saveDO)。 删除的方法用 delete 做前缀。返回受影响行数。 如： Long deleteById(String id)。 修改的方法用 update 做前缀。批量修改时返回受影响行数，单个值修改时返回修改后实体。 如： UserDetailDO|Long updateById(UserDetailDO updateDO)。 如： Long updateByCreateTime(UserDetailDO updateDO,Date createTime)。 执行特定操作的方法使用其操作名做前缀。如： sendSms 发送短信，noticeUser 通知用户，uploadPic 上传图片，downloadFile 下载文件 数据库命名规则 数据库库名命名规则：&lt;产品前缀&gt;_&lt;应用简称&gt;命名 如ng_kboss_auth，其中ng_kboss为产品前缀，auth为应用简称。 如hneduexam应修改为hn_edu_exam，其中hn_edu为产品前缀，exam为应用简称。 表名和字段名均采用小写，以下划线分隔，如collection_account、edu_report_operate_loss_record 如果手动建索引，名称需要使用idx_&lt;表名/表名首字母简写&gt;_&lt;字段名&gt;的模式 数据库中遇到时间字段，需要使用datetime(3)类型,否则会查询时会存在舍入问题 请注意：业务状态字段和软删除字段需要分离，即is_delete字段不能进行业务控制 公共命名规范如下表 字段名 类型 空&#x2F;默认值 描述 备注 is_delete tinyint(4) DEFAULT ‘0’ 软删除字段(0 未删除 1 已删除) - create_time datetime(3) DEFAULT CURRENT_TIMESTAMP 创建时间 - update_time datetime(3) DEFAULT CURRENT_TIMESTAMPON UPDATE CURRENT_TIMESTAMP 更新时间 - create_user_id varchar(32) DEFAULT NULL 创建者id 非必需，视业务而定 create_user_name varchar(255) DEFAULT NULL 创建者名称 非必需，视业务而定 update_user_id varchar(32) DEFAULT NULL 修改者id 非必需，视业务而定 update_user_name varchar(255) DEFAULT NULL 修改者名称 非必需，视业务而定 编码规则 尽量避免使用java.sql.Date，应使用java.util.Date 尽量避免止将SimpleDateFormat等线程不安全的类定义为静态变量。如果定义为 static，必须加锁。 代码开发以及分支规范分支类型 主分支，唯一主分支为master 功能分支，实际进行开发时，开发人员实际编写的分支，以feature/&lt;功能名称&gt;命名 热修复分支，从某个发布分支迁出，完成修复后合并回发布分支和主分支，以hotfix/&lt;release分支版本号&gt;/&lt;需要修复的功能&gt;命名 版本命名规则 命名规则 Maven工件 Artifact Version &lt;框架版本&gt;/&lt;功能版本&gt;/&lt;修订版本&gt; 框架版本: 框架变更时+1功能版本: 功能迭代时+1 (累加，不清零)修订版本: 修复BUG时+1 (累加，不清零) 功能分支 Branch Name feature/&lt;Feature Name&gt;-&lt;Date yyyyMMdd&gt; 测试分支 Branch Name test/&lt;Date yyyyMMdd&gt;/&lt;Feature A&gt;/&lt;Feature B&gt; 热发布分支 Branch Name hotfix/&lt;Feature A&gt;/ 发布标签（单体项目） Release Tag &lt;Artifact Version&gt; 发布标签（聚合项目） Release Tag &lt;Artifact Name&gt;/&lt;Artifact Version&gt; 分支流程介绍123456789101112flowchart TB subgraph multi[单功能开发分支流程] direction LR s_dev(开发) s_feature_test(测试) s_dev -.-&gt; s_feature_test s_dev --&gt; s_pre s_pre(预发\\nmaster分支) s_pre_test(预发布测试) s_prod(发布\\n产品验收\\n打ReleaseTag) s_pre --&gt; s_pre_test --&gt; s_prod end 12345678910111213flowchart TB subgraph multi[多功能开发分支流程] direction LR m_fa(开发A功能\\nfeature分支) m_fb(开发B功能\\nfeature分支) m_fa -.-&gt; test m_fb -.-&gt; test(功能测试\\ntest分支) m_fa --&gt; m_pre_a(预发A功能\\nmaster分支) --&gt; m_pord_a(发布\\n打ReleaseTag) m_fb --&gt; m_pre_b(预发B功能\\nmaster分支) --&gt; m_pord_b(发布\\n打ReleaseTag) end 分支介绍分支类型： 主分支，唯一主分支为master 功能分支，实际进行开发时，开发人员实际编写的分支，以feature/&lt;功能名称&gt;命名 *测试分支，所有含有test/前缀的分支都为测试分支，以test/&lt;对应功能分支的名称&gt;命名 主分支 master对应环境: 预发布环境-pre *生产环境-prod 生命周期: 永久有效 分支特征: 该分支受到保护，无法直接通过push提交代码，仅仅可通过合并PullRequest更新 该分支的代码一定是 可用的 代码，随时随地都可以通过流水线完成构建 线上的应用一定是通过主分支打包得到的 主分支上的代码不一定与线上代码一致 开发人员无需在本地建立同名分支以跟踪master （可选）公共测试分支 test建议命名规范: test\\&lt;Date yyyyMMdd&gt;\\&lt;功能名称A&gt;\\&lt;功能名称B&gt; 对应环境: 测试环境-test (功能测试-多分支) 生命周期: 当多个功能需要并行进行测试时，从任一feature分支中迁出，并merge所有需要测试的分支 当功能均测试完成或仅剩一个功能后，可以删除此分支 分支特征: 该分支用于支持同一项目同时开发、测试多个新功能 同一个项目串行进行开发任务时，此分支无需存在，直接由feature分支代替本分支功能 由于pre测试并不在本分支上运行，所以pre环境做出的改动不会应用到本分支上，本分支的代码不一定准确，非必要不使用本分支做测试 该分支仅进行功能测试 该分支禁止反向合并到其他任何分支 功能分支 feature/&lt;功能名称&gt;-&lt;Date yyyyMMdd&gt;对应环境: 开发环境-dev 测试环境-test (功能测试-单分支) 生命周期: 当开发人员接到开发任务并完成任务拆解后，根据具体的任务创建功能分支 当该功能完成发布，顺利上线并创建release分支后，该功能分支应该被删除 分支特征: 该分支必须也只能从master分支签出 该分支的代码一定是 最新的 代码，由开发人员自行开发和维护 使用该分支的开发人员必须在上班前和下班前从master拉取并合并代码 拉取master发生代码冲突时，如非特意更改，应以master分支代码为准 当测试人员使用此分支进行功能测试 热发布分支 hotfix/&lt;release分支版本号&gt;/&lt;需要修复的功能&gt;对应环境: 生产环境-prod 生命周期: 当生产环境出现bug时，由开发人员从对应的Release Tag中签出 当该bug修复完成后: 移动签出的Release Tag到当前分支 将该分支并入master分支中 删除热发布分支 分支特征: 该分支由开发人员新建，只能从对应的Release Tag中签出 该分支的代码一定是 准确的 可用于生产的 代码，可以随时进行打包上线 该分支应始终落后或等同于master分支 分支管理 GitGraph图例 方块形状节点： 测试提测节点 中空圆形节点： 由merge产生的commit节点 被标签标记的节点： 实际生产上线的节点 最简流程 同时仅有一个功能进行开发时的最简流程，无需test分支，且无pre环境。 %%{init: { 'logLevel': 'debug', 'theme': 'base' ,'startOnLoad': true } }%% gitGraph commit branch feature-a commit commit type:HIGHLIGHT commit type:HIGHLIGHT checkout main merge feature-a commit tag:\"release-A\" Hotfix流程 生产上线后出现重大Bug需要进行线上修复的流程。 1234567891011%%&#123;init: &#123; &#x27;logLevel&#x27;: &#x27;debug&#x27;, &#x27;theme&#x27;: &#x27;base&#x27; ,&#x27;startOnLoad&#x27;: true &#125; &#125;%%gitGraphcommit tag:&quot;release-A&quot;branch hotfixcommitcommit tag:&quot;release-A-2&quot;checkout maincommit tag:&quot;release-B&quot;commit tag:&quot;release-C&quot;commitmerge hotfix 多功能并行开发流程 同时有多个功能进行并行开发时的的复杂管理流程，需要借助一个不可信的临时test分支同时进行多个功能的测试。 123456789101112131415161718192021222324252627282930%%&#123;init: &#123; &#x27;logLevel&#x27;: &#x27;debug&#x27;, &#x27;theme&#x27;: &#x27;base&#x27; ,&#x27;startOnLoad&#x27;: true &#125; &#125;%%gitGraphcommitbranch feature-bbranch feature-acommitcommitcheckout feature-bcommitcommitbranch testmerge feature-acommit type:HIGHLIGHTcheckout feature-acommitcommitcheckout testmerge feature-acheckout mainmerge feature-acommit id:&quot;pre-A-a123&quot; type:HIGHLIGHTcheckout feature-acommitcheckout mainmerge feature-acommit id:&quot;pre-A-a124&quot; type:HIGHLIGHTcommit tag:&quot;release-A&quot;merge feature-bcommit id:&quot;pre-B-a125&quot; type:HIGHLIGHTcommit tag:&quot;release-B&quot;"},{"title":"ReleaseNote-202203025","path":"ReleaseNote-202203025/","text":"将流水线由Travis CI切换为Github Action 域名由note.dreamccc.club切换至note.bequick.run 将主题 Nexmoe 的部署方式由Git-Submodel迁移至NPM 文章和标题图片使用OSS回源叠加CDN，提高大陆地区可用性 基于 hexo-action 定制了打包镜像用以解决境外CDN可用性不高的问题 添加SiteMap并提交至 Google Search Console"},{"title":"Angular项目搭建（三）-集成clarity","path":"Angular项目搭建（三）-集成clarity/","text":"Angular生态下有很多UI框架可以使用，其中不少也是高star的，但我最终还是选择了Clarity。 为什么选Clarity？ Clarity由vmware维护，代码质量相对有保障。 Harbor也是基于Clarity开发的，代码完全开源，可借鉴性很高。 Clarity除了现成的UI组件可以搬运外，还具有一整套设计原则和对设计逻辑的讲解 这第三点，是其他开源UI框架所欠缺的，在项目初期，遵循一个良好的设计原则是非常有必要的，而这正是大多数后端开发所不具备的技能，Clarity很好的弥补了这一点。 &#x2F;&#x2F;TODO 待续写"},{"title":"MIUI清理自带应用","path":"MIUI清理自带应用/","text":"系统版本 Redmi K30S Ultra MIUI 12.5.5.RJDCNXM 稳定版 注意的坑 禁用&#x2F;删除完后需要重启手机看看是否正常，如果出现卡mi，桌面加载不出来等情况，需要立即进入recovery中连接adb修复。 小米浏览器只禁用会出问题，比如通过QQ等打开链接跳转时会无响应，建议直接卸载。 通过adb删除的应用再进行大版本更新时会被重新安装，届时需要再次操作。 删除&#x2F;禁用MIUI系统自带应用 手机连接电脑，同时开发者模式中打开adb调试选项 电脑侧安装ADB 1sudo scoop install adb -g 电脑确认手机adb连接 1adb devices -l 此时手机会弹出adb连接确认弹窗 (可选)打印手机程序包列表 1adb shell pm list packages &gt; miuipackage.txt 删除&#x2F;禁用自带应用 1234567891011121314# 进入交互式adb-shelladb shell# 禁用系统广告apollo:/ $ pm diable-user com.miui.systemAdSolution# 禁用行为分析apollo:/ $ pm disable-user com.miui.analytics# 禁用游戏中心服务apollo:/ $ pm disable-user com.xiaomi.gamecenter.sdk.service # 删除小米浏览器apollo:/ $ pm uninstall --user 0 com.android.browser# 重启手机测试是否正常apollo:/ $ reboot 参考资料 MIUI 强制使用自带浏览器 使用ADB不root删除小米MIUI系统自带应用"},{"title":"Kubernetes安装笔记","path":"Kubernetes安装笔记/","text":"本篇仅纯笔记，记录安装踩坑和一些细节，本次安装也仅仅只安装了3台机器，组建最小集群。 踩的小坑 安装时要么全局走代理，要么走国内镜像(清华源&#x2F;阿里源等) 容器运行时的cGroupDriver一定要与kubelet的配置一致，否则kubelet起不起来，会影响集群的init 集群初始化生成的加入集群的token只有24小时有效期，过期需要重新生成 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# 关闭firewallsystemctl stop firewalld.servicesystemctl disable firewalld.service# 安装bash补全yum install bash-completion# 安装yum管理工具sudo yum install -y yum-utils# 添加EPEL源curl -s -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# 安装Dockeryum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repoyum install docker-ce docker-ce-cli containerd.iosystemctl enable dockersystemctl start docker# 添加K8sRepo - Google/Aliyun源cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo \\[kubernetes] \\name=Kubernetes \\# baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch \\baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 \\gpgcheck=1 \\repo_gpgcheck=1 \\# gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg \\gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg \\exclude=kubelet kubeadm kubectl \\EOF# Set SELinux in permissive mode (effectively disabling it)sudo setenforce 0sudo sed -i &#x27;s/^SELINUX=enforcing$/SELINUX=permissive/&#x27; /etc/selinux/config# 安装kube工具集yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes# 启动kubeletsystemctl enable --now kubelet# 预下载初始化集群需要的源 - Aliyun源kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers -v=7# 打印用于kubeadm init的默认配置kubeadm config print init-defaults &gt; init-default.yml# 如有必要，需要修改配置vim init-default.yml# #1 如果init-default.yml配置了cgroupDriver=systemd，需要将CRI的driver改为相同的值# https://stackoverflow.com/questions/43794169/docker-change-cgroup-driver-to-systemdcat &lt;&lt;EOF | tee /etc/docker/daemon.json \\&#123; \\ &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;] \\&#125; \\EOFsystemctl restart docker# 开始初始化集群kubeadm init --config init-default.yml -v=7# 配置kubectlmkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config# 配置kubectl自动完成## UserProfileecho &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt;~/.bashrc## SystemProfilekubectl completion bash | sudo tee /etc/bash_completion.d/kubectl &gt; /dev/null init-default.yml用于集群初始化的配置文件，可以通过kubeadm config print init-defaults得到 123456789101112131415161718192021222324252627282930313233343536apiVersion: kubeadm.k8s.io/v1beta3bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfiguration---# 配置cgroupDriver 推荐使用systemd (#1)# https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/kind: KubeletConfigurationapiVersion: kubeadm.k8s.io/v1beta3cgourpDriver: systemd---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta3certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: &#123;&#125;etcd: local: dataDir: /var/lib/etcd# 更换了镜像仓库# imageRepository: k8s.gcr.ioimageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: 1.23.0networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;"},{"title":"清理linux磁盘空间","path":"清理linux磁盘空间/","text":"首先查看是哪块挂载的磁盘满了 1234567891011121314151617181920212223df -hdaizc@DAIZC:~/.local/share/Trash/files$ df -h文件系统 容量 已用 可用 已用% 挂载点udev 12G 0 12G 0% /devtmpfs 2.4G 189M 2.2G 8% /run/dev/sdb4 92G 69G 18G 80% /tmpfs 12G 290M 12G 3% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 4.0M 0 4.0M 0% /sys/fs/cgroup/dev/loop0 128K 128K 0 100% /snap/bare/5/dev/loop1 255M 255M 0 100% /snap/gnome-3-38-2004/106/dev/loop2 62M 62M 0 100% /snap/core20/1518/dev/loop4 92M 92M 0 100% /snap/gtk-common-themes/1535/dev/loop3 401M 401M 0 100% /snap/gnome-3-38-2004/112/dev/loop5 82M 82M 0 100% /snap/gtk-common-themes/1534/dev/sdb2 9.8G 37M 9.3G 1% /recoverytmpfs 2.4G 136K 2.4G 1% /run/user/1000/dev/sda2 224G 168G 57G 75% /media/daizc/软件/dev/loop6 62M 62M 0 100% /snap/core20/1581/dev/loop7 62M 62M 0 100% /snap/core20/1587/dev/loop8 584M 584M 0 100% /data/uengine/data/rootfsuengine-fuse 92G 69G 18G 80% /data/uengine/安卓应用文件 因为整个磁盘都挂在根目录下，所以只知道根目录满了，不知道具体是满的是什么 这里需要一层一层向下找 1234567891011daizc@kl-All-Series:~$ sudo du -h --max-depth=1 |sort -hr |head -n 102.1G .378M ./service223M ./logs187M ./.vscode-server140M ./seata105M ./docker-image13M ./.kube12M ./sandbox8.5M ./.local7.7M ./.cache"},{"title":"Angular初学排坑日记（二） windows软链接惨案","path":"Angular初学排坑日记（二）windows软链接惨案/","text":"上文讲到已经成功创建了Angular项目，现在总得跑下DEMO来试试水吧，于是打开webstorm导入项目，单击播放键。好家伙，新错误来了。 12345678910111213D:\\Users\\Link\\WebstormProjects\\angularDemo\\src\\polyfills.ts - Error: Module build failed (from D:\\Users\\Link\\WebstormPro ojects\\angularDemo\\node_modules\\@ngtools\\webpack\\src\\ivy\\index.js):Error: D:\\Users\\Link\\WebstormProjects\\angularDemo\\src\\polyfills.ts is missing from the TypeScript compilation. Please ma ake sure it is in your tsconfig via the &#x27;files&#x27; or &#x27;include&#x27; property. at D:\\Users\\Link\\WebstormProjects\\angularDemo\\node_modules\\@ngtools\\webpack\\src\\ivy\\loader.js:60:26** Angular Live Development Server is listening on localhost:4200, open your browser on http://localhost:4200/ ** × Failed to compile.√ Browser application bundle generation complete. 编译失败，但浏览器启动成功。弹出一个明晃晃的Cannot GET /。 仔细看了下报错，但完全没明白这个提示的意思，感觉就是说src\\polyfills.ts没找到，所以ts编译失败啥的，让我检查tsconfig里是否有配置files或者include属性。 1234567891011121314&#123; &quot;extends&quot;: &quot;./tsconfig.json&quot;, &quot;compilerOptions&quot;: &#123; &quot;outDir&quot;: &quot;./out-tsc/app&quot;, &quot;types&quot;: [] &#125;, &quot;files&quot;: [ &quot;src/main.ts&quot;, &quot;src/polyfills.ts&quot; ], &quot;include&quot;: [ &quot;src/**/*.d.ts&quot; ]&#125; 但是很遗憾的是，配置里都有配，但这个问题还是出现了，于是开始google。 Angular5 :polyfills.ts &amp; \\main.ts is missing from the TypeScript compilation感觉和我的症状很相似。这位朋友告诉我们修改angular.json添加一个属性就可以了。lines123456&#123; &quot;projects&quot;: &#123; &quot;anglarDemo2&quot;: &#123; &quot;architect&quot;: &#123; &quot;build&quot;: &#123; &quot;options&quot;: &#123; &quot;preserveSymlinks&quot;: true // 《==========加的这行 再次启动项目，已经可以正常启动了。随后根据上面的属性搜索了一下相关的资料，找到一个issues main.ts is missing from de TypeScript compilation 总而言之就是windows软链接惹的祸，angular需要在配置里设置保留逻辑链接才能正常的读到文件。起因是我在装系统时为了节约C盘的空间，将C:\\User\\Link这个目录通过Symlink的方式挂载到了D盘导致触发了这个报错。"},{"title":"Angular初学排坑日记（一）cnpm安装惨案","path":"Angular初学排坑日记（一）cnpm安装惨案/","text":"最近做中间件开发，涉及到不少的项目改造，发现有不少中间件的前端都是拿Angular写的，自己看Angular看不太懂，前端同事都是vue玩家，也不太玩得转这玩意儿，但是改不动中间件的前端的确蛮吃亏，再加上之前群里朋友煽风点火，于是有了折腾下Angular的念头。正好拿了台新电脑来玩，准备整个Angular玩玩，于是直接拿scoop配环境配好了node环境和npm。 初始环境 node:16.13.1 npm:8.1.2 直连npm源会走代理，下载略慢，于是顺手装个cnpm 1PS C:\\Users\\Link\\WebstormProjects&gt; npm install -g cnpm 接着装angular-cli 1PS C:\\Users\\Link\\WebstormProjects&gt; cnpm install -g @angular/cli 淘宝源装着就是快，不到10s装好了，接着就是跟着官方文档初始化项目 12345PS C:\\Users\\Link\\WebstormProjects&gt; ng new angulardemo? Would you like to add Angular routing? Yes? Which stylesheet format would you like to use? SCSS [ https://sass-lang.com/documentation/syntax#scss ]setTimeout is not defined ? 不知什么情况，报了个setTimeout的错误，本菜鸡不是很懂，遂Google一下，说是cnpm的问题（*不知为何会有这问题，有待查验）。总之先把这俩卸载掉。 123PS C:\\Users\\Link\\WebstormProjects&gt; cnpm uninstall -g @angular/cliPS C:\\Users\\Link\\WebstormProjects&gt; npm uninstall -g cnpmPS C:\\Users\\Link\\WebstormProjects&gt; npm cache clean --force 然后只好用npm重新安装cli。但是npm安装的确是慢，而且个人喜欢用yarn做依赖管理，于是安装yarn，在龟速安装的同时，顺便找到个换源的工具。 123456789101112PS C:\\Users\\Link\\WebstormProjects&gt; scoop install -g yarnPS C:\\Users\\Link\\WebstormProjects&gt; yarn global add yrmPS C:\\Users\\Link\\WebstormProjects&gt; yrm ls* npm ---- https://registry.npmjs.org/ cnpm --- http://r.cnpmjs.org/ taobao - https://registry.npm.taobao.org/ nj ----- https://registry.nodejitsu.com/ rednpm - http://registry.mirror.cqupt.edu.cn/ npmMirror https://skimdb.npmjs.com/registry/ edunpm - http://registry.enpmjs.org/ yarn --- https://registry.yarnpkg.comPS C:\\Users\\Link\\WebstormProjects&gt; yrm use taobao 成功解决问题 12PS C:\\Users\\Link\\WebstormProjects&gt; yarn global add @angular/cliPS C:\\Users\\Link\\WebstormProjects&gt; ng new angulardemo1"},{"title":"JobDescription-20210916","path":"JobDescription-20210916/","text":"JobDescription-A招个人只接流程引擎 岗位要求: 加分项任选其一即可 3年以上IT互联网行业或软件行业后端开发工作经验，优秀者可适当放宽年限。 良好的Java基本功，理解OOP、DDD等编程方式。 熟悉BPMN2.0规范，熟悉开源流程引擎（不限于flowable）工作原理。 熟悉常用的设计模式，具备一定源码阅读能力。 熟悉Linux系统，能熟练的使用Linux的常用命令。 [加分项] 能合理抽离业务代码和可复用的组件，具有封装内部工具的经验。 [加分项] 能着手优化结构不合理的sql语句，并能根据业务场景提出优化方案。 [加分项] 能根据实际业务场景合理应用缓存(包括但不限于Redis、Memcached)、消息(包括但不限于RabbitMq、Kafka)、搜索引擎(Elasticsearch、solr)等中间件。 工作职责: 负责应用系统设计、编码、优化工作，并为团队中其他成员提供技术支持。 进行需求分析，拆分业务任务，编写技术文档。 JobDescription-B招个人整个中台一起接 岗位要求: 加分项任选其一即可 3年以上IT互联网行业或软件行业后端开发工作经验，优秀者可适当放宽年限。 良好的Java基本功，理解OOP、DDD等编程方式。 熟悉常用的设计模式，具备一定源码阅读能力。 具备优秀的接口设计能力，能在合适的位置适当地预留扩展的空间。 具备良好的抽象能力，能合理抽离业务代码和可复用的组件，具有封装内部工具的经验。 熟悉微服务框架（不限于SpringCloud）,分布式设计和应用。 熟悉Linux系统，能熟练的使用Linux的常用命令。具备git分支管理能力。 [加分项] 熟悉BPMN2.0规范，熟悉开源流程引擎（不限于flowable）工作原理。 [加分项] 能着手优化结构不合理的sql语句，并能根据业务场景提出优化方案。 [加分项] 能根据实际业务场景合理应用缓存(包括但不限于Redis、Memcached)、消息(包括但不限于RabbitMq、Kafka)、搜索引擎(Elasticsearch、solr)等中间件。 工作职责: 负责应用系统设计、编码、优化工作，并为团队中其他成员提供技术支持。 进行需求分析，拆分业务任务，编写技术文档。"},{"title":"书单整理(2021/08/30)","path":"书单整理2021-08-30/","text":"建议部门采购的书单，有意向可以参考一下 书单整理(2021&#x2F;08&#x2F;30)自己整理的查漏补缺(给部门所有人选的) 码农翻身 入门用基础书，适用2年以下经验 图灵经典计算机基础图书 强烈推荐下面该丛书 网络是怎样连接的 面向对象是怎样工作的 程序是怎样跑起来的 计算机是怎样跑起来的 部门首选 代码整洁之道+程序员的职业素养 强烈推荐前面一本。 后面那姊妹书主要是讲故事的，可选 架构整洁之道 流程的永恒之道：工作流及BPM技术的理论、规范、模式及最佳实践 重构 改善既有代码的设计 Java语言版 扩展书单（自己想要的） 数据密集型应用系统设计 [Designing Data-Intensive Applications] 分布式系统应用设计 [Designing Distributed Systems] 后端同事A 数据结构与算法分析–java语言描述 深入理解计算机系统(CSAPP) 前端同事 前端同事B ES6标准入门（第3版） 前端同事C 深入理解ES6 前端同事D JavaScript高级程序设计 第4版(图灵出品） 前端同事E TypeScript项目开发实战 [Advanced TypeScript Programming Projects]"},{"title":"[DEBUG日记]Swagger扫不到类-Jdk代理导致的反射类型故障","path":"[DEBUG日记]Swagger扫不到类-Jdk代理导致的反射类型故障/","text":"先说结论jdk代理的问题，换用cglib代理就好了。随便找个配置类，加上 @EnableAspectJAutoProxy注解即可解决。 整理接口后突然暴毙整理了一下项目中的Controller，然后有几个接口就扫描不到了。无论怎么更换扫描注解都找不到这些接口，甚至使用包路径扫描都找不到，很是魔幻。 哪痛治哪俗话说哪里痛治哪里，既然swagger扫不到接口，就先看看swagger到底是怎么去扫接口的 先看swagger的配置12345678910111213@Bean(&quot;docket&quot;)public Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() // 扫描带Api注解的类 .apis(RequestHandlerSelectors.withClassAnnotation(Api.class)) .paths(PathSelectors.any()) .build() .securitySchemes(securitySchemes()) .globalOperationParameters(globalOperationParameters()) ;&#125; 再看上文中.apis()这个接口的源码1234public ApiSelectorBuilder apis(Predicate&lt;RequestHandler&gt; selector) &#123; requestHandlerSelector = requestHandlerSelector.and(selector); return this;&#125; 看这方法签名，返回值是this没啥用,直接忽略。入参是个将RequestHandler处理成布尔值的函数， 根据其变量名selector可以猜测其作用是传入一个RequestHandler判断其是否满足条件,这里的条件是指啥？当然是指我们从外部传进来的RequestHandlerSelectors.withClassAnnotation(Api.class)这个玩意儿啦！ 在深入我们传入的RequestHandlerSelectors.withClassAnnotation(Api.class)中，看他的源码：123456789/** * Predicate that matches RequestHandler with given annotation on the declaring class of the handler method * * @param annotation - annotation to check * @return this */public static Predicate&lt;RequestHandler&gt; withClassAnnotation(final Class&lt;? extends Annotation&gt; annotation) &#123; return input -&gt; declaringClass(input).map(annotationPresent(annotation)).orElse(false);&#125; 这里是判断是否满足条件的关键位置，每一个RequestHandler(就是上面的input)都会通过上文的表达式判断得到一个布尔值 再继续往前找到调用这个函数的地方12345678910111213141516171819202122232425262728293031323334353637// 上面第二点的位置是在ApiSelectorBuilder中，要想找到第三点的函数真正在哪里被使用了，需要反向找回去// 在springfox.documentation.spi.service.contexts.ApiSelector中找到了我们传入的`private final Predicate&lt;RequestHandler&gt; requestHandlerSelector;`// 通过其getter反向找回去// 找到了springfox.documentation.spring.web.scanners.ApiListingReferenceScanner#scan public ApiListingReferenceScanResult scan(DocumentationContext context) &#123; LOG.info(&quot;Scanning for api listing references&quot;); Map&lt;ResourceGroup, List&lt;RequestMappingContext&gt;&gt; resourceGroupRequestMappings = new HashMap&lt;&gt;(); int requestMappingContextId = 0; ApiSelector selector = context.getApiSelector(); // 看这里，要找的东西就在这里 Iterable&lt;RequestHandler&gt; matchingHandlers = context.getRequestHandlers().stream() .filter(selector.getRequestHandlerSelector()).collect(toList()); for (RequestHandler handler : matchingHandlers) &#123; ResourceGroup resourceGroup = new ResourceGroup( handler.groupName(), handler.declaringClass(), 0); RequestMappingContext requestMappingContext = new RequestMappingContext( String.valueOf(requestMappingContextId), context, handler); resourceGroupRequestMappings.putIfAbsent( resourceGroup, new ArrayList&lt;&gt;()); resourceGroupRequestMappings.get(resourceGroup).add(requestMappingContext); ++requestMappingContextId; &#125; return new ApiListingReferenceScanResult(resourceGroupRequestMappings);&#125; 打上断点开始Debug，看看controller有没有被swagger扫到发现swagger是直接从spring中取出的RequestHandler，而我们的Controller是被Spring正常扫描的(废话，没被Spring扫到都不能用了好吧) 前往步骤3处打上条件断点？？？这是咋回事 继续排查草，这个类被jdk代理了，这直接导致反射获取类型的时候获取到了jdk的Proxy$?.class这个类型，从而导致检查注解失败declaringClass()方法原本应该获取到声明类，我们预计他应该会返回我们Controller的真实类型，但是由于Controller实现了一个接口，导致Spring使用了jdk代理这个对象，从而导致获取声明类时获取到了jdk代理所用的类型，最终导致获取注解失败 问题清楚了，都是jdk代理的锅，那么我们有多个方法解决这个问题： 使用继承代替实现 使用cglib代替jdkProxy进行代理 最终解决 由于这里定义在Controller上的的接口是由其他模块的spi，为了保证调用安全，因此采用方式2来解决1234567// 随便找个配置类加注解@EnableAspectJAutoProxy( // 示代理应由 AOP 框架公开为ThreadLocal以通过org.springframework.aop.framework.AopContext类进行检索 exposeProxy = true, // 指示是否要创建基于子类 (CGLIB) 的代理，而不是基于标准 Java 接口的代理 proxyTargetClass = true ) 采用jdk的方式代理会更快，相较于cglib会有一定的性能提升，但应该仅在启动时有提升，类加载完毕Bean注册完成后应该都是一样的，随口BB一句没有验证过是否正确。 最后上个图对比一下"},{"title":"PDF疑难杂症","path":"PDF疑难杂症以及治疗方法总结/","text":"PDF是一个由Adobe编写现由国际标准化组织 (ISO) 维护的一个开放式标准，PDF 文档可以包含链接和按钮、表单域、音频、视频和业务逻辑。这种文件可进行电子签名，因此政府机构大量在用，但是仍然是个煞笔格式。 编辑PDF相关的建议 IText有一整套pdf模板生成-填充-签名的工具链，如果公司愿意可以直接买服务，如果不愿意使用，那至少在pdf模板制作时需要统一PDF编辑工具。 IText工具集中包含一个itext-rups，该工具能展示pdf的结构树，方便debug 推荐使用的pdf编辑工具为PDF-XChange Editor和Adobe Acrobat DC 填充PDF容易遇到的问题文本域无法填充中文检查文本框中使用的字体是否内嵌在Pdf中,如果没有内嵌，那么随便找一个文字，将该文字的字体设置为需要内嵌的字体并保存即可 减小pdf的体积可以使用编辑工具优化pdf，将未使用的字体都清理出pdf，pdf将只保留使用过的字形，这可能会影响不带字体的文本域填充 文本域填充图片在pdf标准中未定义图片文本域，当下的图片文本域都是基于ButtonField变形的，所以只需要给这个Button设置背景图片或者直接设置值为Base64即可 按钮填充样式异常pdf并未通过类型区分单选/复选框，而是为按钮定义了一系列的属性来决定其行为和样式 其中有一个样式列表，当按钮的value命中样式列表的key时，就会应用样式列表预定义的样式 因此直接检查为按钮填充的值是否与pdf工具中定义`按钮值`一致即可 *需要注意样式列表的key不能是中文，在`Acrobat`中`按钮值`被设置为中文时，会将`按钮值`定义在该按钮的opt属性中，在样式列表中定义key`&quot;0&quot;`，再将opt的属性映射过去，这种情况并不受大部分PDF的操作工具的支持，但是可以直接将按钮值填充为`&quot;0&quot;`来解决这个问题"},{"title":"解决由https转发导致的SpringCloudGateway转发异常","path":"解决由https转发导致的SpringCloudGateway转发异常/","text":"错误日志如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546472021-07-27 15:51:31.302 WARN [TID:TID-1419928421240946688][PID:1][or-http-epoll-2] r.netty.http.client.HttpClientConnect [299]: [id: 0xe9859259, L:/10.42.8.227:41228 ! R:10.42.4.120/10.42.4.120:8080] The connection observed an errorio.netty.handler.codec.DecoderException: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 485454502f312e31203430302042616420526571756573740d0a436f6e74656e742d4c656e6774683a20300d0a436f6e6e656374696f6e3a20636c6f73650d0a0d0a at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:477) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:795) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748)Caused by: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 485454502f312e31203430302042616420526571756573740d0a436f6e74656e742d4c656e6774683a20300d0a436f6e6e656374696f6e3a20636c6f73650d0a0d0a at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1213) Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException:Error has been observed at the following site(s): |_ checkpoint â‡¢ org.springframework.cloud.gateway.filter.WeightCalculatorWebFilter [DefaultWebFilterChain] |_ checkpoint â‡¢ com.alibaba.csp.sentinel.adapter.spring.webflux.SentinelWebFluxFilter [DefaultWebFilterChain] |_ checkpoint â‡¢ org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain] |_ checkpoint â‡¢ HTTP GET &quot;/某个service/v2/api-docs&quot; [ExceptionHandlingWebHandler]Stack trace: at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1213) at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1280) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:446) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:795) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) 问题描述这是一个很奇怪的只在测试环境存在的异常。生产环境一切正常，测试环境访问以http访问正常，以https访问出现出现500错误。 开发架构 spring-boot:2.3.12.RELEASE spring-cloud:Hoxton.SR8 spring-cloud-alibaba:2.2.5.RELEASE 生产环境链路：1访问域名 =公网dns=&gt; 云服务商slb =lb&amp;https转http=&gt; ingress-nginx =lb=&gt; service-gateway =lb=&gt; service 测试环境链路：1访问域名 =内网dns=&gt; ingress-nginx =lb&amp;https转http=&gt; service-gateway =lb=&gt; service Debug思路 查看应用日志发现service并未收到该请求，请求在service-gateway已经失败了，判断是网关问题。 查看网关日志发现报错（见文章一开始处的日志）。 请求在nettyClient处的SSLHandler报错，说明网关的filter流程已经走完 最终异常是NotSslRecordException，直译为非SSL记录异常，不知道为啥会抛出这个异常 在网关中加日志走一波，打印这个请求的所有HttpHeader，对比问题请求与正常请求的特征 查看问题请求的Header 123456789header: Host: &quot;aaa-bbb-test.xxx.com&quot;, X-Scheme: &quot;https&quot; X-Request-ID: &quot;37cd98713db6b101d813171e0be609a&quot;, X-Forwarded-For: &quot;aaa-bbb-test.xxx.com&quot;, X-Forwarded-Port: &quot;443&quot;, X-Forwarded-Proto: &quot;https&quot;, referer: &quot;https://aaa-bbb-test.xxx.com/doc.html&quot;, ....此处略过ContentType、Accept Header中有转发来源的部分头部，先尝试在Filter中除掉这些头部试试 1234567891011public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest serverHttpRequest = exchange.getRequest().mutate() .headers(h -&gt; &#123; h.remove(&quot;X-Forwarded-For&quot;); h.remove(&quot;X-Forwarded-Port&quot;); h.remove(&quot;X-Forwarded-Proto&quot;); &#125;) .build(); return chain.filter(exchange.mutate().request(serverHttpRequest).build());&#125; 然而并没有什么卵用，异常依旧。 根据异常堆栈可知，是在发起请求时出现问题，尝试找到请求发起类 由于网关使用webflux导致通过日志查看的堆栈的信息不够全面，通过本地调试正常请求查看异步堆栈跟踪到请求发起类NettyRoutingFilter 110行处发现一个协议判断的代码 123456789101112131415 public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; URI requestUrl = exchange.getRequiredAttribute(GATEWAY_REQUEST_URL_ATTR); String scheme = requestUrl.getScheme(); if (isAlreadyRouted(exchange) || (!&quot;http&quot;.equals(scheme) &amp;&amp; !&quot;https&quot;.equals(scheme))) &#123; return chain.filter(exchange); &#125; setAlreadyRouted(exchange); ... ``` - 这个`scheme`控制了网关向其他服务的转发协议，决定这个变量的是`requestUrl`- `requestUrl`是从exchange取出来的，通过查看`GATEWAY_REQUEST_URL_ATTR`这个常量的引用，找到了`requestUrl` 的来源`ReactiveLoadBalancerClientFilter#filter[113]`- 发现源码注释 // if the `lb:&lt;scheme&gt;` mechanism was used, use `&lt;scheme&gt;` as the default, // if the loadbalancer doesn&#39;t provide one. 1- 根据源码注释修改网关的配置 修改前: [ &#123; &quot;id&quot;: &quot;service-a&quot;, &quot;name&quot;: &quot;A服务&quot;, &quot;predicates&quot;: [&quot;Path=/service-a/**&quot;], &quot;filters&quot;: [], &quot;uri&quot;: &quot;lb://service-a&quot; &#125; ] 修改后: [ &#123; &quot;id&quot;: &quot;service-a&quot;, &quot;name&quot;: &quot;A服务&quot;, &quot;predicates&quot;: [&quot;Path=/service-a/**&quot;], &quot;filters&quot;: [], &quot;uri&quot;: &quot;lb:http://service-a&quot; &#125; ] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 4. 服务恢复正常了## 找到根本原因 #### 整理出SpringCloudGateway的请求处理流程的关键类： 1. 由LoadBalancerUriTools计算scheme、host、port。其中scheme由`overrideScheme`和`` 1. `org.springframework.cloud.gateway.filter.ReactiveLoadBalancerClientFilter#filter[108]` 2. `org.springframework.cloud.client.loadbalancer.LoadBalancerUriTools#doReconstructURI[100]` 2. 共享 GATEWAY_REQUEST_URL_ATTR 变量给其他的Filter 1. `org.springframework.cloud.gateway.filter.ReactiveLoadBalancerClientFilter#filter[113]` 2. `org.springframework.cloud.gateway.filter.NettyRoutingFilter#filter[108]` 3. 交由Netty发起请求 1. `org.springframework.cloud.gateway.filter.NettyRoutingFilter#filter[108]`#### 问题发生在第一步：由LoadBalancerUriTools计算scheme、host、port 1. 在ReactiveLoadBalancerClientFilter中，主要逻辑如下 ```java return choose(exchange).doOnNext(response -&gt; &#123; if (!response.hasServer()) &#123; throw NotFoundException.create(properties.isUse404(), &quot;Unable to find instance for &quot; + url.getHost()); &#125; URI uri = exchange.getRequest().getURI(); // if the `lb:&lt;scheme&gt;` mechanism was used, use `&lt;scheme&gt;` as the default, // if the loadbalancer doesn&#x27;t provide one. String overrideScheme = null; if (schemePrefix != null) &#123; overrideScheme = url.getScheme(); &#125; DelegatingServiceInstance serviceInstance = new DelegatingServiceInstance( response.getServer(), overrideScheme); URI requestUrl = reconstructURI(serviceInstance, uri); if (log.isTraceEnabled()) &#123; log.trace(&quot;LoadBalancerClientFilter url chosen: &quot; + requestUrl); &#125; exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, requestUrl); &#125;).then(chain.filter(exchange)); 此处的overrideScheme就是刚才配置中添加的http:,这是优先级最高的配置 然后response.getServer()和overrideScheme被送入委派类DelegatingServiceInstance中，项目中ServiceInstance的实现类是NacosServiceInstance 紧接着reconstructURI(serviceInstance, uri);被执行，重建后的URI的scheme、host、port都是从ServiceInstance中获取的 由于NacosServiceInstance没实现getScheme()，因此进入接口的default方法返回null值 org.springframework.cloud.gateway.support.DelegatingServiceInstance#getScheme[76] org.springframework.cloud.client.ServiceInstance#getScheme[71] 由于路由配置和服务实例中都没有取到scheme最终选取了原始URI中的scheme org.springframework.cloud.client.loadbalancer.LoadBalancerUriTools#computeScheme NettyRoutingFilter将Response原样送出，协议是https内容是http，因此导致在建立TLS链接时发生了异常 org.springframework.cloud.gateway.filter.NettyRoutingFilter#filter[147]"},{"title":"发码平台结构设计","path":"发码平台结构设计/","text":"同事接到个任务要做一个发码平台，但产品没说清楚怎么做，也不造要做成什么样子。虽然跟我没关系，但由于之前就对发码平台的实现逻辑感兴趣，因此基于兴趣进行了业务设计，这里简单记录个人的一些想法。 需求猜测如果只是为了保证公司内所有的券码的唯一性，那我觉得做一个随机数生成器就足够了，做成平台级的功能没有意义，基于此进行需求猜测： 唯一性保证：保证业务平台内券码唯一性 券码生成管理：能查看每种优惠券的生成以及使用情况 批量生成券码：一次返回限量的券码给业务端 券码核销：核销并同步回调业务端。 唯一性保证缩短雪花位数这个好说。保证唯一性的算法多得很，听到这个需求就想到使用雪花ID。但产品冒出来说要求券码长度在10位以内，这个需要斟酌一下。想了一下，雪花ID是64位二进制数,如果把base提高，那么位数就会下降。随便做个测试： 1234public static void main(String[] args) &#123; System.out.println(Long.toString(SnowflakeIdUtil.generateId(), 32));&#125;// output =&gt; gjnk3gf62400 32进制下只有12个字符了，加把劲把进制弄成64试试： 1234public static void main(String[] args) &#123; System.out.println(Long.toString(SnowflakeIdUtil.generateId(), 64));&#125;// output =&gt; 598684081116483584 输出变成十进制了，感觉有问题，进去看看代码： 12345678java.util.Long: public static String toString(long i, int radix) &#123; // Look Here！ MIN_RADIX = 2 MAX_RADIX = 36 if (radix &lt; Character.MIN_RADIX || radix &gt; Character.MAX_RADIX) radix = 10; if (radix == 10) return toString(i); ...... Long这个类中的toString做了限制，只能将number表示为2-36进制编码的字符串,因为(0-9)+(a-z)刚好36个字符。这里没有考虑到大写字符也可以来做编码，如果加上A-Z的大写字符，就有62个字符可用，可以将这个long表示为62进制的字符串，字符串内无特殊字符，既好看又不用考虑转义。 测试Base62： 12345使用hutool的Base62：public static void main(String[] args) &#123; System.out.println(Base62.encode(Longs.toByteArray(nextId)));&#125;// output =&gt; iDzwMuZe76 需求满足！ 不连续性这个着实有点头疼，思考了一下把这个拆解为两个部分 业务线隔离总的来说就是要让同一时间内每个业务线生成的ID不连续，这样可以充分降低每个业务线之间券码冲突的可能性（虽然雪花ID本来就不冲突，只要时间不被NTP回调）。 从SnowFlake类本身着手，由于我们应用跑在k8s内，本身就有全系统唯一的标识，且实例数也不会大于32，所以这里近似的任务SnowFlake中的datacenterId和workId没必要都用，这里将容器的Id对32取余作为datacenterId(此处可能会导致冲突，后期可以与运维协商为容器编号，这里使用编号即可)，再对业务方提供的业务Id对32取余作为workId，这样基本达成了通过业务线隔离Id的要求。11101010111101100010010110000000000 同一批券码隔离虽说同一批券码生成之间不冲突，但是由于雪花ID尾数是个序列，同一批券码生成出来尾数是连续的，这可能会导致相邻的券码被盗用，因此同一批券码隔离也是有必要的。 还是打算从SnowFlake类着手，64位数，每一位都有用处，其中时间戳占用的空间比较大，占用了整整11位。要想腾空间，就只有拿时间戳开刀了。 首先我们计算1年的时间用时间戳表示需要多长： 123456789101112131415161718192021毫秒*秒*分*时*天1000*60*60*24*365 = 31536000000 = 0b111010101111011000100101100000000001年时间需要35个二进制位表示，剩下6个二进制位，可以提供出0b111111(64)个位置31536000000*3 = 0b10110000001110001001110000100000000003年的时间需要37个二进制位来表示，剩下4个二进制位，可以提供处0b1111(16)个位置给用户猜测31536000000*5 = 0b100100101101100111010111011100000000005年的时间需要38个二进制位来表示，剩下3个二进制位，可以提供处0b111(8)个位置给用户猜测感觉差不多了，就用38个二进制位:38个二进制位0b11111111111111111111111111111111111111 = 274877906943274877906943/1000/3600/24 约 3181.46天 合 8.7年 如此这般，便省下来3个二进制位和时间戳前面的符号位一起组成4个二进制位用于放猜解，可以提供16种组合 这里吐槽一下，这个限制10位要求全局唯一要求生成性能高还要抗猜解真的有点过分，当然雪花算法也并不特别适合这种场景，有其他好的方案就更好了。 后续重写Snowflake类，重新设置位移位数并新增抗猜解位数就可以了。 业务以及表结构设计这个功能说来简单，其实也有不明确的点： 一次要生成多少张券？每一批券需不需要记录批次？ 是即时生成还是仅记录数量用时再取？ 需要管理什么字段？ 就个人想法来说，先假设每个系统会有一个账户，系统收到钱后会生成订单，根据订单数额，找本系统添加对应数量的券码。但是由于生成的数量较多，因此在这里并不会真正地生成券码，只会记录该系统拥有对应数量的券码额度。随后调用获取券码接口时，再生成券码，再通过限制该接口的调用频率和最大券码数来控制性能消耗。 最终交互设计图如下： 生成管理表设计(省略大家都有的字段) generate_manage field(驼峰&#x2F;下划线脑内自行转换) type function id varchar(32) - systemId varchar(32) 具体业务线Id systemName varchar(128) 业务系统名冗余在此避免远程查表 type varchar(64) 这批券码的生成方式(SNOWFLAKE_LITE&#x2F;UUID) total bigint 该批次拥有的券码总数 current bigint 该批次已生成的券码总数（保证原子性） systemName varchar(128) 业务系统名冗余在此避免远程查表 businessTypeTemplate varchar(64) [模板]提供给业务方存储业务上的类型在获取券码时可以覆盖该值可能是以后做查询的条件 businessDataTemplate json [模板]提供给业务方存储该批次券码的公有属性在获取券码时可以覆盖该值券码被消费时将返给业务方 callbackTemplate json [模板]券码被消费回调地址在获取券码时可以覆盖该值 createTime date(3) - 生成操作记录表设计(省略大家都有的字段) generate_operation field(驼峰&#x2F;下划线脑内自行转换) type function id varchar(32) - manageId varchar(32) 关联generate_manage total bigint 该批次拥有的券码总数 original bigint 消费前数量 consumption bigint 本次消费数量 remaining bigint 剩余消费数量 createTime date(3) - 券码表设计 coupon field(驼峰&#x2F;下划线脑内自行转换) type function id varchar(32) - manageId varchar(32) 关联 generate_manage operationId varchar(32) 关联 generate_operation systemId varchar(32) [冗余以避免连表]具体业务线Id systemName varchar(128) [冗余以避免连表]业务系统名冗余在此避免远程查表 generateTime date(3) [冗余以避免连表]券码生成时间 code varchar(32) 这个才是券码 businessType varchar(32) 提供给业务方存储业务上的类型可能是以后做查询的条件 businessData json 提供给业务方存储该批次券码的公有属性券码被消费时将返给业务方 callback json 券码被消费回调地址，格式为map为升级预留空间Map&lt;String callbackUrl,String callbackVersion&gt; createTime date(3) - 生成&#x2F;获取券码APIrequest field(驼峰&#x2F;下划线脑内自行转换) type function manageId String 关联 generate_manage businessType String — businessData JSONObject — callback Map&lt;String,String&gt; — response field(驼峰&#x2F;下划线脑内自行转换) type function operation GenerateOperation coupons List&lt;Coupon&gt;"},{"title":"定制Jackson注解实现字段脱敏","path":"定制jackson注解/","text":"功能在保证jackson原注解不失效的前提下，通过自定义注解对POJO中部分指定的字段进行自定义处理 完成样式1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String[] args) throws JsonProcessingException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setAnnotationIntrospector(new EnhanceJacksonAnnotationIntrospector()); A a = new A(); a.setAge(10); a.setName(&quot;ASDASDASD&quot;); a.setRemark(&quot;REMARK!&quot;); a.setMobile(&quot;17600000000&quot;); System.out.println(objectMapper.writeValueAsString(a)); &#125; @Data static class A &#123; private String name; private Integer age; private String remark; @JsonMask(a = &quot;&quot;,b = &quot;&quot;,c = &quot;&quot;) private String mobile; &#125;&#125; 运行结果1&#123;&quot;name&quot;:&quot;ASDASDASD&quot;,&quot;age&quot;:10,&quot;remark&quot;:&quot;REMARK!&quot;,&quot;mobile&quot;:&quot;1760****000&quot;&#125; 核心逻辑实现逻辑比较简单，核心类只有两个: Jackson注解拦截器 com.fasterxml.jackson.databind.introspect.JacksonAnnotationIntrospector Json序列化器 com.fasterxml.jackson.databind.JsonSerializer Jackson序列化逻辑: 首先看到这里com.fasterxml.jackson.databind.ObjectMapper#_configAndWriteValue，这个方法根据objectMapper实例中的config创建对应的JsonGenerator并序列化value。 追踪到com.fasterxml.jackson.databind.ser.DefaultSerializerProvider#serializeValue根据源码可知，在序列化时使用哪个JsonSerializer是由com.fasterxml.jackson.databind.SerializerProvider#findTypedValueSerializer决定的，SerializerProvider.findTypedValueSerializer就是序列化器提供者.根据value类型查找序列化器。 !(三句源码注释)[]根据三句源码注释可知，jackson在这里维护了一个本地缓存一个共享缓存，在两个缓存都没找到的时候再通过com.fasterxml.jackson.databind.SerializerProvider#findValueSerializer获取新的序列化器并存入缓存。 进入到com.fasterxml.jackson.databind.SerializerProvider#findValueSerializer内部，再次进行了缓存查找，在都没有命中的情况下，调用com.fasterxml.jackson.databind.SerializerProvider[521]的_createAndCacheUntypedSerializer去创建序列化器。 快进到com.fasterxml.jackson.databind.ser.BeanSerializerFactory#createSerializer,这里是构建序列化器的真实逻辑。注意下findSerializerFromAnnotation(prov, beanDesc.getClassInfo())这个方法，根据方法名直译就是根据注解获取序列化器。 进入到com.fasterxml.jackson.databind.ser.BasicSerializerFactory#findSerializerFromAnnotation内部，发现Jackson获取序列化器分为两步: 调用prov.getAnnotationIntrospector().findSerializer(a)找到序列化器的class，随后在prov.serializerInstance(a, serDef)中实例化改序列化器 调用prov.getAnnotationIntrospector().findSerializer(a)直接获取JsonSerializer类型的实例，随后在prov.serializerInstance(a, serDef)中强转为JsonSerializer&lt;?&gt; 快进到com.fasterxml.jackson.databind.AnnotationIntrospector#findSerializer，这里具体使用的是JacksonAnnotationIntrospector类。这个类中定义了jackson中的序列化和反序列化有关的注解及其对应的处理方式。 进入到com.fasterxml.jackson.databind.introspect.JacksonAnnotationIntrospector.findSerializer，发现这里处理了两个注解@JsonSerialize、@JsonRawValue，找到注解的情况下new出了对应的序列化器，没有找到任何注解返回了null。 到此为止&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 根据上面整理的逻辑。要想jackson处理自定义注解，就必须给jackson配置一个自定义的AnnotationIntrospector，如果这里手动实现AnnotationIntrospector接口，那么jackson自带的注解都会失效，因此选择继承原有的JacksonAnnotationIntrospector类。在这个类中，可以通过返回不同的序列化器来控制序列化的具体行为，其方法入参Annotated类实际上是对被序列化字段的类型的包装。但注意，在AnnotationIntrospector中是无法拿到被序列化的值本身的，只能拿到字段的相关信息。 重写重写JacksonAnnotationIntrospector 增强Jackson注解处理器1234567891011121314151617181920212223242526272829/** * &lt;h2&gt;增强Jackson注解处理器&lt;/h2&gt; * * @author Daizc-kl * @date 2020/12/9 17:27 */public class EnhanceJacksonAnnotationIntrospector extends JacksonAnnotationIntrospector &#123; @Override public Object findSerializer(Annotated a) &#123; // 调用父类逻辑保证原注解继续生效 Object serializer = super.findSerializer(a); // Jackson原装进口注解优先 if (serializer == null) &#123; // 只对Getter生效 if (a instanceof AnnotatedMethod) &#123; // 返回值类型为String if (a.getType().getRawClass().equals(String.class)) &#123; // 头上有MaskProperty注解 JsonMask jsonMask = a.getAnnotation(JsonMask.class); if (null != jsonMask) &#123; // 实例化出自己的序列化器并返回 return new MaskMethodSerializer(jsonMask); &#125; &#125; &#125; &#125; return serializer; &#125;&#125; 重写JsonSerializer 序列化器12345678910111213141516171819202122/** * &lt;h2&gt;xxx方法序列化器&lt;/h2&gt; * * @author Daizc-kl * @date 2020/12/9 18:23 */public class MaskMethodSerializer extends JsonSerializer&lt;String&gt; &#123; // 字段上的注解本身 private final JsonMask jsonMask; public MaskMethodSerializer(JsonMask jsonMask) &#123; this.jsonMask = jsonMask; &#125; @Override public void serialize(String value, JsonGenerator gen, SerializerProvider serializers) throws IOException &#123; // 自定义序列化行为 // 略...... gen.writeString(&quot;...最终输出的字符串...&quot;); &#125;&#125;"},{"title":"[ESP8266]02_Lua基础","path":"[ESP8266]02_Lua基础/","text":""},{"title":"[ESP8266]01_刷写测试AT固件","path":"[ESP8266]01_刷写测试AT固件/","text":""},{"title":"改造Spring-data-redis 优雅设置过期时间","path":"改造Spring-data-redis/","text":"Spring-data-redis是一个比较优雅的缓存解决方案，只需要在对应的方法上打上注解就可以便捷的将数据放入redis。 但Spring-data-redis中配置TTL只能按照cacheName的维度进行配置，并不能精确到具体的接口上。 比如以下需求就不能优雅的实现： 1234567891011121314public interface CacheDemo&#123; // 这个接口只缓存30min @Cacheable(value = &quot;user&quot;, keyGenerator = &quot;xxxx&quot;) List&lt;User&gt; listByQuery(UserQuery query); // 这个接口只缓存1min @Cacheable(value = &quot;user&quot;, keyGenerator = &quot;xxxx&quot;) List&lt;User&gt; takeUserFromObj(Object obj); // 这个接口缓存180min @Cacheable(value = &quot;user&quot;, keyGenerator = &quot;xxxx&quot;) List&lt;User&gt; getByUserId(String userId);&#125; 这篇文章就将以定制Cache具体实现类的方式优雅的实现这个功能."},{"title":"Death_Standing","path":"Death_Standing/","text":"前言 三个月前《死亡搁浅》发售时，没有人想到里面近未来的世界观，会成为中国当下的现实。各地限制交通，封城断路，我们成了United Cities of China。人们离群索居，恐惧无声蔓延，病毒有如天上淅淅沥沥的时间雨，吞噬着希望和快乐。一旦死去，尸体必须马上就近火化，生者无法举行任何仪式。就连抢夺货物囤积在自己营地的米尔人也真实地还原了。快递员孤独地在路上奔波着，送药物，送口罩，送食品——一如游戏里的披萨和香槟。货物被留在冷冰冰的丰巢，小区门口的桌子上。因为没有3D投影，下单的人们甚至不能和快递员说一句赞美和感谢。不知道这样的日子还要过多久，如果有PS4，不妨买一份《死亡搁浅》，感受一下另一个相似的世界。即使在最冰冷和孤独的荒野，也能响起Low Roar的歌。———转自weibo:lilimarleen 先吹一波 世界观庞大且严谨，随着主线推进逐渐解锁世界的真相。 游戏内容重复但却不枯燥，即使是同一个任务，也有无数种不同的完成方式。 优美的风景辅以悠扬的音乐实在是画龙点睛之用。 所有出场的人物角色都是根据真人3D建模的，在剧情中有很大的代入感。 不足之处 顽人的伏笔还没收呢，是要出续作的节奏？ 难度设置不均衡，前三章缺乏有效抗BT武器（其实前三章都是新手教程，真实的走路模拟器），容易劝退新玩家。左下雪山区难度也十分劝退。 缺乏互动性，该作只能与其他玩家建造的建筑互动，无法和其他快递员一起飙车还是蛮遗憾的。 小彩蛋 在点赞数比较多的小石堆休息会加快体力恢复速度。 在点赞数比较多的蘑菇堆旁能捉到隐生虫，捉完记得浇花。 在点赞数比较多的小石堆和蘑菇堆旁呼喊能够得到不明人员的回应和祝福！ 运送mama和开罗尔艺术家的时候可以绕道和妹子一起去泡温泉！！ 如果在生日那天送快递，对周围呼喊时会有不明人员祝你生日快乐！！！ 白金感言整个作品给人最大的印象就是干净。剧情中有一个相当重要的意象：绳子。绳子象征着连接，将各地孤立无援的人们连在一起、互相帮助，共同对抗末日。而整部游戏更是宣扬的人性至善,不管走到哪里，都会得到其他玩家的帮助，只要帮助过别人，便能收获他人的赞赏与激励。这种受到他人赞美与感谢的感觉真是令人沉迷其中。 这款游戏的神奇之处就在于：并非玩家挑选游戏，而是让游戏来挑选玩家！ 对于习惯于快节奏对抗的玩家来说，这款游戏极有可能与他们无缘——被劝退于前两章的新手教程，而留存下来的玩家则是适合慢节奏大片时间游玩的玩家，只有被筛选出来的玩家才有机会尽情享受这款游戏带来的震撼与感动。 一句话总结这个作品前无古人，不知道后是否有来者。"},{"title":"java8函数设计[1]-在filter中根据Key去重的函数","path":"java8函数设计[1]-在filter中根据Key去重的函数/","text":"函数接口是如何写出来的？ java函数接口设计在filter中根据Key去重的函数 StreamUtil.distinctByKey()具体使用方法 该函数用于在filter中根据传入参数的某一属性进行过滤，以保证在收集为map的情况下不会出现重复主键 1234List&lt;entry&lt;string, string=&quot;&quot;&gt;&amp;gt; simpleList = baseProjects.stream() .filter(StreamUtil.distinctByKey(BaseProject::getTypeDic)) .map(StreamUtil.entry(BaseProject::getTypeDic, BaseProject::getTypeStr)) .collect(Collectors.toList()); 接口设计123456789101112/** * &lt;h3&gt;distinctByKey&lt;/h3&gt; * &lt;p&gt;可用于在filter中根据属性过滤&lt;/p&gt; * * @param function 接受一个 接受 类型A 返回 类型B 的函数式接口 * @return Predicate 返回一个 接受 类型A 返回 Boolean型 的函数式接口 */public static &lt;t&gt; Predicate&lt;t&gt; distinctByKey(Function&lt;!--? super T, ?--&gt; function) &#123; Map filterMap = Maps.newConcurrentMap(); return t -&amp;gt; filterMap.putIfAbsent(function.apply(t), Boolean.TRUE) == null;&#125; 设计思路 观察Stream.filter()接口 对接Stream.filter()接口 实现去重功能 参数优化 开始编写观察Stream.filter()接口 &amp;&amp; 对接Stream.filter()接口 Stream.filter()接口:Stream&lt;t&gt; filter(Predicate&lt;!--? super T--&gt; predicate) 首先可以看到filter接口需要接收一个类型为Predicate&lt;!--? super T--&gt;的函数,这个函数接受一个参数返回一个boolean类型。 根据以上信息先写一个函数出来 123456789public static &lt;e&gt; Predicate&lt;e&gt; distinctByKey2() &#123; return new Predicate&lt;e&gt;() &#123; @Override public boolean test(E e) &#123; return false; &#125; &#125;; &#125; 这个函数虽然可以被filter正常接收，但是由于没有形参，因此无法传递参数 123456public static void main(String[] args) &#123; Lists.newArrayList() .stream() .filter(StreamUtil.distinctByKey2()) .collect(Collectors.toList()); &#125; 现在与预期的效果比对一下 对比 函数 目前效果 .filter(StreamUtil.distinctByKey2()) 预期的效果 .filter(StreamUtil.distinctByKey2(Xxxxx:getId)) 有点不对？！这个函数虽然可以被filter正常接收，但是去无法传入参数。因此要给distinctByKey2()方法加上传入的参数。 通过观察预期效果，是需要传入的参数应该是一个函数的，这个函数接收一个T类型参数，返回一个不知道什么类型的参数。 Function&lt;t, r=&quot;&quot;&gt;函数接收一个T类型，返回一个R类型，可以满足这个需求。 继续观察预期效果，这个不知道什么类型的参数实际上就是distinctByKey2方法中new出来Predicate&lt;e&gt;#test(E e)中的那个e，说人话就是Function&lt;t,r&gt;中的R在此处就是Predicate&lt;e&gt;中的E。 那么补上我们的形参 123456789public static &lt;e,r&gt; Predicate&lt;e&gt; distinctByKey2(Function&lt;e,r&gt; function) &#123; return new Predicate&lt;e&gt;() &#123; @Override public boolean test(E t) &#123; return false; &#125; &#125;; &#125; 实现去重功能现在与预期效果一致了，需要实现去重功能 去重功能可以用Set或者ConcurrentMap实现使用ConcurrentMap存储function返回值的状态根据ConcurrentMap.putIfAbsent(xxx)的特性 如果map中已经有同样的key和value就返回null，根据返回值是否为null来判断是否需要被过滤 12345678910111213141516public static &lt;e,r&gt; Predicate&lt;e&gt; distinctByKey2(Function&lt;e,r&gt; function) &#123; Map filterMap = Maps.newConcurrentMap(); return new Predicate&lt;e&gt;() &#123; @Override public boolean test(E t) &#123; // 调用方传入函数的结果 R apply = function.apply(t); // putIfAbsent 在首次关联K,V时返回null 非首次的时候不执行put()方法 直接返回之前的值 Boolean isNullIsDuplicate = filterMap.putIfAbsent(apply, Boolean.TRUE); // isNullIsDuplicate==null时 K就没重复 函数返回true return isNullIsDuplicate == null; &#125; &#125;; &#125; 参数优化把匿名内部类使用lambda替换掉，在把冗余代码inline，最后调整一下泛型参数 在上面的例子中`Function&lt;e,r&gt;`中 R是调用者函数的返回值类型，仅仅被当做key使用，本身是什么类型不重要，因此可以直接去掉这个R泛型，由?代替 E是调用者函数的形参类型，函数调用方在函数中可能会显式声明参数类型`[注1]`，以达到强转形参类型的目的，因此将E修改为 &lt;!--? super E--&gt; 1234567891011121314public static &lt;e&gt; Predicate&lt;e&gt; distinctByKey2(Function&lt;!--? super E, ?--&gt; function) &#123; Map filterMap = Maps.newConcurrentMap(); return e -&amp;gt; filterMap.putIfAbsent(function.apply(e), Boolean.TRUE) == null; &#125; //[注1] public static void main(String[] args) &#123; List collect = Lists.newArrayList() .stream() // 显式强转形参类型 .filter(StreamUtil.distinctByKey2(baseEntity -&amp;gt; baseEntity)) .collect(Collectors.toList()); &#125;"},{"title":"[Zookeeper学习-第一章]zk环境搭建[单机+控制台]","path":"[Zookeeper学习-第一章]zk环境搭建[单机+控制台]/","text":"系统环境为 Centos ，由于项目需要，准备搭建 zookeeper-3.5.5 + 用于方便展示节点的zookeeperAdmin用作公司开发之用 zookeeper-3.5.5下载前往开源项目下载页面根据需要下载对应的版本（注意要下载文件名后面带”-bin”的包）懒人链接 123456789101112131415161718192021222324[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# tar -zxvf ./apache-zookeeper-3.5.5-bin.tar.gz[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# cd ./apache-zookeeper-3.5.5-bin.tar.gz[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# lltotal 44drwxr-xr-x 2 2002 2002 4096 Apr 9 19:13 bindrwxr-xr-x 2 2002 2002 4096 Sep 20 14:00 confdrwxr-xr-x 5 2002 2002 4096 May 3 20:07 docsdrwxr-xr-x 2 root root 4096 Sep 20 13:40 lib-rw-r--r-- 1 2002 2002 11358 Feb 15 2019 LICENSE.txtdrwxr-xr-x 2 root root 4096 Sep 20 13:43 logs-rw-r--r-- 1 2002 2002 432 Apr 9 19:13 NOTICE.txt-rw-r--r-- 1 2002 2002 1560 May 3 19:41 README.md-rw-r--r-- 1 2002 2002 1347 Apr 2 21:05 README_packaging.txt[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# ll[root@iZuf6imeqt5e7fo9jw7918Z apache-zookeeper-3.5.5-bin]# cd conf[root@iZuf6imeqt5e7fo9jw7918Z conf]# lltotal 16-rw-r--r-- 1 2002 2002 535 Feb 15 2019 configuration.xsl-rw-r--r-- 1 2002 2002 2712 Apr 2 21:05 log4j.properties-rw-r--r-- 1 2002 2002 922 Feb 15 2019 zoo_sample.cfg[root@iZuf6imeqt5e7fo9jw7918Z conf]# cp ./zoo_sample.cfg ./zoo.cfg[root@iZuf6imeqt5e7fo9jw7918Z conf]# cd ../bin/[root@iZuf6imeqt5e7fo9jw7918Z conf]# 需要留意的如果在这里直接启动的话可能会启动不成功，因为apache-zookeeper默认监听了8080端口作为自己的zookeeper-server的服务端。最好是自己在.&#x2F;conf&#x2F;zoo.cfg中配置一下admin.serverPort=[自己随便改个端口]，对的，配置文件里默认是没有这行的，这个比较坑。 启动12345678910111213141516[root@iZuf6imeqt5e7fo9jw7918Z bin]# ./zkServer.sh start/usr/bin/javaZooKeeper JMX enabled by defaultUsing config: /app/zookeeper/apache-zookeeper-3.5.5-bin/bin/../conf/zoo.cfgStarting zookeeper ... STARTED[root@iZuf6imeqt5e7fo9jw7918Z bin]# ./zkServer.sh start/usr/bin/javaZooKeeper JMX enabled by defaultUsing config: /app/zookeeper/apache-zookeeper-3.5.5-bin/bin/../conf/zoo.cfgStarting zookeeper ... already running as process 29414.[root@iZuf6imeqt5e7fo9jw7918Z bin]# ./zkServer.sh status/usr/bin/javaZooKeeper JMX enabled by defaultUsing config: /app/zookeeper/apache-zookeeper-3.5.5-bin/bin/../conf/zoo.cfgClient port found: 2181. Client address: localhost.Mode: standalone zookeeper-admin这是一个github上的小项目功能不多，刚刚够用就行，不整那些花里胡哨的，支持直接使用docker构建，非常方便 12345[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# docker run --name zookeeper-admin -p 80:2182 docker.io/ahoowang/zookeeper.admin[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES56bf5522f4fe 4232addbc345 &quot;dotnet ZooKeeper....&quot; About an hour ago Up 2 minutes 0.0.0.0:2182-&amp;gt;80/tcp zookeeper-admin 界面看上去还不错。 然而好景不长，跑了一阵发现无法访问了。 12[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ??? 怎么停止了，看看日志怎么说 1234567891011121314151617181920[root@iZuf6imeqt5e7fo9jw7918Z zookeeper]# docker logs 56bf5522f4feHosting environment: ProductionContent root path: /appNow listening on: http://+:80Application started. Press Ctrl+C to shut down.Application is shutting down...Hosting environment: ProductionContent root path: /appNow listening on: http://+:80Application started. Press Ctrl+C to shut down.Unhandled Exception: System.InvalidOperationException: Collection was modified; enumeration operation may not execute. at System.ThrowHelper.ThrowInvalidOperationException(ExceptionResource resource) at System.Collections.Generic.Dictionary`2.ValueCollection.Enumerator.MoveNext() at ZooKeeper.Admin.ZooKeeperManager.&lt;dispose&gt;d__9.MoveNext() in E:\\ZooKeeper-Admin\\ZooKeeper.Admin\\ZooKeeperManager.cs:line 55--- End of stack trace from previous location where exception was thrown --- at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state) at System.Threading.QueueUserWorkItemCallback.System.Threading.IThreadPoolWorkItem.ExecuteWorkItem() at System.Threading.ThreadPoolWorkQueue.Dispatch()"},{"title":"[Zookeeper学习-第二章]用作SpringCloud的注册中心","path":"[Zookeeper学习-第二章]用作SpringCloud的注册中心/","text":"太长懒得写了 用作注册中心-&gt;手动维护节点-&gt;节点树操作 最后配合feign完成服务动态调用"},{"title":"计划任务的Spring实现与手动实现","path":"计划任务的Spring实现与手动实现/","text":"手写计划任务当然比不过简单又好用的SpringScheduled 使用Spring Scheduled的计划任务关键方法 计算下一次匹配CRON表达式的时间 new CronSequenceGenerator(&quot;1 1 0 1 * ?&quot;).next(new Date()); 该方法用于计算下一次运行的到现在时间的时间差 org.springframework.scheduling.concurrent.ReschedulingRunnable#schedule(); 实现代码12345678910111213141516171819/** * &lt;h2&gt;ScheduleConfig&lt;/h2&gt; * &lt;p&gt;定时任务配置&lt;/p&gt; * * @author Daizc * @date 2019/12/10 */@Component@EnableSchedulingpublic class ScheduleConfig &#123; // 每月第一天的0分0秒执行 public static final String CRON_EXPRESSION = &quot;0 0 0 1 * ?&quot;; @Scheduled(cron = CRON_EXPRESSION, zone = &quot;Asia/Shanghai&quot;) public void generateFormJob() &#123; System.out.println(new Date().toString() + &quot; &amp;gt;&amp;gt;计划任务执行....&quot;); &#125;&#125; 自己写的计划任务思路 使用一个阻塞队列 使用一个线程去消费队列 使用一个线程在计算现在到下次执行时间的时间差并睡到下次执行时间将Runable放入队列中消费 实现代码12345678910111213141516171819202122232425262728293031323334353637383940/** * 自己写的计划任务 */private LinkedBlockingQueue&lt;runnable&gt; queue = new LinkedBlockingQueue&amp;lt;&amp;gt;();private Runnable task = () -&amp;gt; &#123; System.out.println(new Date().toString() + &quot; &amp;gt;&amp;gt;计划任务执行....&quot;);&#125;;@SuppressWarnings(&#123;&quot;all&quot;, &quot;AlibabaAvoidManuallyCreateThread&quot;&#125;)public ScheduleConfig() &#123; Thread take = new Thread(() -&amp;gt; &#123; try &#123; while (true) &#123; Runnable runnable = runnable = queue.take(); runnable.run(); &#125; &#125; catch (InterruptedException ignored) &#123;&#125; &#125;); take.setDaemon(true); take.setName(&quot;schedule-take&quot;); Thread put = new Thread(() -&amp;gt; &#123; Runnable runnable = null; try &#123; while (true) &#123; // 计算下次执行时间 Date next = new CronSequenceGenerator(CRON_EXPRESSION).next(new Date()); Thread.sleep(next.getTime() - System.currentTimeMillis()); queue.put(task); &#125; &#125; catch (InterruptedException ignored) &#123;&#125; &#125;); put.setDaemon(true); put.setName(&quot;schedule-put&quot;); take.start(); put.start();&#125;"},{"title":"[MXCHIP-2]真机调试","path":"[MXCHIP-2]真机调试/","text":"离上一篇文章发布已经时隔很久了，整理了一下最近学习的操作做个记录免得忘掉了。 真机调试本次的主角 X讯TC1插排 通过仔细观察可以发现，在PCB上预留了2组(8个)触点，一组上面标有RX&#x2F;TX字样，那肯定就是UART接口了。 另一组标有CLK、BIO字样，应该是用于刷机的SWD接口。 引用的资料 模块文档从官网翻到了模块的参数信息DS0021CN_EMW3031_V1.4"},{"title":"SpringBoot中的redis密码问题","path":"SpringBoot中的redis密码问题/","text":"由于站点迁移导致的数据丢失，该文章已做归档处理直接说结论： 使用 spring.redis.url 时，需要把密码拼在url上，下方的password此时不起作用 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 原正文 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 很简单的一个问题，花了大力气去解决。重要的是解决问题的方式和思路。 出现问题出问题的配置如下 application.yml 123456789101112spring: redis: # REDIS_URL url: redis://192.168.1.233:6379 # 如果有密码 password: testpassword123 # 存储到分区1 database: 1 # 默认超时2000 timeout: 3000 报错的日志 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[20190827 20:42:53] ERROR 7900 --- [nio-8086-exec-2] c.z.v.d.a.c.mvc.GlobalExceptionHandler : Unable to connect to Redis; nested exception is io.lettuce.core.RedisCommandExecutionException: NOAUTH Authentication required.org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis; nested exception is io.lettuce.core.RedisCommandExecutionException: NOAUTH Authentication required. at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1092) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1065) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:865) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:340) at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:238) at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:109) at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:82) at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58) at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:73) at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:554) at org.springframework.cache.interceptor.CacheAspectSupport.findCachedItem(CacheAspectSupport.java:519) at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:401) at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:345) at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:61) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.zunchen.video.dmp.service.impl.onvif.OnvifDeviceCacheServiceImpl$EnhancerBySpringCGLIB$913f47a3.connectOnvifDevice(&lt;generated&gt;) at com.zunchen.video.dmp.admin.api.ConnectDeviceApiController.connect(ConnectDeviceApiController.java:36) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:890) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:154) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:122) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:107) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)Caused by: io.lettuce.core.RedisCommandExecutionException: NOAUTH Authentication required. at io.lettuce.core.ExceptionFactory.createExecutionException(ExceptionFactory.java:135) at io.lettuce.core.LettuceFutures.awaitOrCancel(LettuceFutures.java:122) at io.lettuce.core.AbstractRedisAsyncCommands.select(AbstractRedisAsyncCommands.java:1194) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at io.lettuce.core.FutureSyncInvocationHandler.handleInvocation(FutureSyncInvocationHandler.java:57) at io.lettuce.core.internal.AbstractInvocationHandler.invoke(AbstractInvocationHandler.java:80) at com.sun.proxy.$Proxy206.select(Unknown Source) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1087) ... 69 common frames omitted 查询资料 spring boot 配置redis 报错 NOAUTH Authentication required springboot整合redis报错NOAUTH Authentication required.解决方案 归纳 大多解决方案都是通过配置注入的RedisConfig来setPassword解决的，SpringBoot未注入密码的原因仍然不明。 原因探究原因分析 由报错信息可以看出，最终抛出的异常是io.lettuce.core.RedisCommandExecutionException，其中lettuce不知道是什么。 通过查阅资料 高级的 Redis Java 客户端 Lettuce 得知lettuce是springboot2.0中用来代替jedis的新的redis客户端。 那为何lettuce为何会报错呢？这是我最大的疑惑，我决定去spring.redis的自动配置类中看看到底发生了什么 源码跟踪&gt; spring.redis的自动配置包：org.springframework.boot.autoconfigure.data.redis 看着这个目录结构，第一反应直奔LettuceConnectionConfiguration中去看源码。 在其构造方法处打断点发现是拿到了密码的，发现同类下有一方法createLettuceConnectionFactory();明显是创建连接工厂的方法，断点套上去。 这个方法中干了啥，它看了看配置文件中有没有包含${spring.redis.sentinel}和${spring.redis.cluster}的配置，如果有就拿对应的配置去创建连接工厂。但是yml中既没有配置哨兵模式也没有配置集群模式，所以进入独立模式getStandaloneConfig(); 顺手计算一下，看看standaloneConfig长什么样子…..嗯???!!!……密码呢？……发生了啥？ 问题找到了，感觉自己好蠢。 解决问题修改配置1234567891011121314spring: redis: # REDIS_URL 中自己带上密码 # Connection URL. Overrides host, port, and password. User is ignored. Example: # redis://user:password@example.com:6379 # url: redis://UserIsIgnored:testpassword123@192.168.1.233:6379 # HOST 和 PASSWORD 是一套配置 host: 192.168.1.233 # 如果有密码 （用于RedisTemplate ，Lettuce不会拿这个password） password: testpassword123 # 存储到分区1 database: 1 # 默认超时2000 timeout: 3000 修改后启动： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273[20190828 03:15:04] ERROR 8564 --- [nio-8086-exec-2] c.z.v.d.a.c.mvc.GlobalExceptionHandler : Unable to connect to Redis; nested exception is io.lettuce.core.RedisCommandExecutionException: NOAUTH Authentication required.org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis; nested exception is io.lettuce.core.RedisCommandExecutionException: NOAUTH Authentication required. at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1092) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1065) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:865) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:340) at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:238) at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:109) at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:82) at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58) at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:73) at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:554) at org.springframework.cache.interceptor.CacheAspectSupport.findCachedItem(CacheAspectSupport.java:519) at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:401) at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:345) at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:61) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.zunchen.video.dmp.service.impl.onvif.OnvifDeviceCacheServiceImpl$EnhancerBySpringCGLIB$b001f767.connectOnvifDevice(&lt;generated&gt;) at com.zunchen.video.dmp.admin.api.ConnectDeviceApiController.connect(ConnectDeviceApiController.java:36) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:890) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:154) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:122) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:107) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) 仍然在报错，这下尴尬了。 再次解决问题 径直来到报错信息提示的地方，估计是红框出出现了异常。此处调用的是接口方法，不知道进了那个方法，没关系，打个断点强制步入。 有点懒，不想解释了，直接画图，发现是redisURISupplier中的password仍然是空的。不想知道为什么了，我只想解决问题。源码点过去看下。 查看该类的构造方法，这个东西正在解析RedisURI，那RedisURI哪儿来的呢？配置里配的呗。 成功解决问题1234567891011121314spring: redis: # REDIS_URL 中自己带上密码 # Connection URL. Overrides host, port, and password. User is ignored. Example: # redis://user:password@example.com:6379 url: redis://UserIsIgnored:testpassword123@192.168.1.233:6379 # HOST 和 PASSWORD 是一套配置 # host: 192.168.1.233 # 如果有密码 （用于RedisTemplate ，Lettuce不会拿这个password） # password: testpassword123 # 存储到分区1 database: 1 # 默认超时2000 timeout: 3000 这次好了，redis成功连接。大功告成。"},{"title":"泛型上下界","path":"泛型上下界/","text":"java的泛型基于类型擦除机制 super 类型下界通配符 List中只能存储一种元素，此处声明的&lt;!--? super BaseDemoEntity--&gt;,表明这个List中存放的元素属于 BaseDemoEntity 其中一种 父类类型 BaseDemoEntity的父类可能有复数个，比如 Object，BaseEntity。取出时不知道到底List里到底装的啥，但一定是继承于Object，所以统一强转为Object类型 存入时只能放入 BaseDemoEntity 和它的子类，因为声明的&lt;!--? super BaseDemoEntity--&gt;，BaseDemoEntity 可以被安全的强转为&lt;!--? super BaseDemoEntity--&gt;此处如果传入BaseDemoEntity的父类，那么运行时jvm将传入的类型转为&lt;!--? super BaseDemoEntity--&gt;时可能会因为类型不一致报错 123456789@RequestMapping(&quot;/superBaseDemoEntity&quot;)public void superBaseDemoEntity() &#123; List&lt;!--? super BaseDemoEntity--&gt; appList = new ArrayList&amp;lt;&amp;gt;(); appList.add(new Music()); appList.add(new BaseDemoEntity()); Object object1 = appList.get(0);&#125; extends 类型上界通配符 &lt;!--? extends BaseDemoEntity--&gt; &#x3D;&gt; BaseDemoEntity的任意一种子类 List中只能存储一种元素，此处声明的&lt;!--? extends BaseDemoEntity--&gt;表明这个List中存放的元素可能是继承与 BaseDemoEntity 的 其中一种 元素 取出时可以被安全的强转为 BaseDemoEntity 存入时由于不知道你存入的类型是否跟&lt;!--? extends BaseDemoEntity--&gt;类型是一个类型，因此不能存入 1234567 @RequestMapping(&quot;/extendsBaseDemoEntity&quot;)public void extendsBaseDemoEntity() &#123; List&lt;!--? extends BaseDemoEntity--&gt; appList2 = new ArrayList&amp;lt;&amp;gt;(); BaseDemoEntity baseDemoEntity = appList2.get(0);&#125;"},{"title":"好用常用人人都要会的最基本的Maven插件收集","path":"好用常用人人都要会的最基本的Maven插件收集/","text":"把手上的好几个项目的pom整理了一遍 规范了一下model 整理出了一些插件 方便新手们入门maven 好用常用人人都要会的最基本的Maven插件收集大部分的插件其实都可以从MAVEN官方的可用插件列表中直接找到在这里取了比较常用并且实用的几个插件做一点说明大多数使用场景无非是： 要自定义打包的名称 要将打包后的jar包自动复制到某处 要将外置lib目录和maven依赖一起打进去 要根据环境复制对应的配置文件 这里选出的插件足以应对大部分情况了 Maven依赖管理插件maven-dependency-plugin主要用于管理依赖，比如引入某个特殊的jar包，或者从某个jar包中提取文件tree命令和display-ancestors命令在搭建工程时是比较好用的，可以很方便的找出重复依赖项，保证依赖版本一致 常用功能 list 列出的依赖关系 tree 以树型结构列出的依赖关系 copy-dependencies 拷贝某个依赖项 unpack-dependencies 解包某个依赖项 display-ancestors 显示所有父依赖 Maven构建小助手 build-helper-maven-plugin主要用于为POM生成各种属性,比如打包时间、IP地址之类的，功能比较多就不上代码了。 常用功能 add-source 将更多source目录添加到POM add-test-source 将更多test source目录添加到POM add-resource 将更多resource directories目录添加到POM add-test-resource 将更多test resource directories目录添加到POM attach-artifact Attach additional artifacts to be installed and deployed. 不知道???干啥的 maven-version 获取Maven核心版本 regex-property 使用正则生成某个属性 regex-properties使用正则生成属性 released-version Resolve the latest released version of this project. parse-version Parse the version into different properties. remove-project-artifact 用于在构建过程中删除某个作为依赖的项目以节省空间 reserve-network-port 保留一个未使用的端口号的随机列表 local-ip 获取当前主机IP cpu-count 获取当前主机CPU核心数 timestamp-property 生成一个事件放入指定属性中 常用于在包名上附加打包时间 uptodate-property 检查某个属性根据检查结果设置其他属性 uptodate-properties 检查多个属性根据检查结果设置多个其他属性 rootlocation 重定义多模块构建的根目录 复制并重命名插件 Copy Rename Maven Plugin功能字如其名,就是用来复制和重命名的，可以用来复制打包好的jar包，也可以在打包过程中复制文件。 常用功能 copy 复制 rename 重命名 没了 一个小栗子123456789101112131415161718&lt;plugin&gt; &lt;groupid&gt;com.coderplus.maven.plugins&lt;/groupid&gt; &lt;artifactid&gt;copy-rename-maven-plugin&lt;/artifactid&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-file&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;sourcefile&gt;target/$&#123;project.build.finalName&#125;.jar&lt;/sourcefile&gt; &lt;destinationfile&gt;/xingyi/$&#123;project.build.finalName&#125;.jar&lt;/destinationfile&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; Maven编译插件 maven-compiler-plugin主要用于设定编译环境和编译器的属性,是比较基础的插件 123456789101112131415161718192021222324252627282930 &lt;plugin&gt; &lt;groupid&gt;org.apache.maven.plugins&lt;/groupid&gt; &lt;artifactid&gt;maven-compiler-plugin&lt;/artifactid&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;!-- 一般而言，target与source是保持一致的，但是，有时候为了让程序能在其他版本的jdk中运行(对于低版本目标jdk，源代码中不能使用低版本jdk中不支持的语法 )，会存在target不同于source的情况 --&gt; &lt;!-- 源代码使用的JDK版本 --&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;!-- 需要生成的目标class文件的编译版本 --&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;!-- 字符集编码 --&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;showwarnings&gt;true&lt;/showwarnings&gt; &lt;!-- 要使compilerVersion标签生效，还需要将fork设为true，用于明确表示编译版本配置的可用 --&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;!-- 指定插件将使用的编译器的版本 --&gt; &lt;compilerversion&gt;1.5&lt;/compilerversion&gt; &lt;!-- 编译器使用的初始内存 --&gt; &lt;meminitial&gt;128m&lt;/meminitial&gt; &lt;!-- 编译器使用的最大内存 --&gt; &lt;maxmem&gt;512m&lt;/maxmem&gt; &lt;!--使用指定的javac命令，例如：&lt;executable&gt;$&#123;JAVA_1_4_HOME&#125;/bin/javac&lt;/executable&gt; --&gt; &lt;executable&gt;&lt;!-- path-to-javac --&gt;&lt;/executable&gt; &lt;!-- 跳过测试 --&gt; &lt;skiptests&gt;true&lt;/skiptests&gt; &lt;!-- 这个选项用来传递编译器自身不包含但是却支持的参数选项--&gt; &lt;compilerargument&gt;-verbose -bootclasspath $&#123;java.home&#125;\\lib\\rt.jar&lt;/compilerargument&gt; &lt;/configuration&gt;&lt;/plugin&gt; SpringBootMaven插件spring-boot-maven-pluginconfiguration.layout&#x3D;ZIP 的用处资料 How to really package and deploy a Spring Boot application 作用将该工程的布局改为ZIP布局，所有的lib将外置到jar包外，在打包时将com.example:demo下的所有依赖放入外置的lib目录 1234567891011121314151617&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupid&gt;org.springframework.boot&lt;/groupid&gt; &lt;artifactid&gt;spring-boot-maven-plugin&lt;/artifactid&gt; &lt;configuration&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;includes&gt; &lt;include&gt; &lt;groupid&gt;com.example&lt;/groupid&gt; &lt;artifactid&gt;demo&lt;/artifactid&gt; &lt;/include&gt; &lt;/includes&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;"},{"title":"[MXCHIP-1]开发板到手","path":"[MXCHIP-1]开发板到手/","text":"这是一个从没玩过单片机开发的菜鸡闲暇时间瞎折腾的故事 起因是18年斐讯出事的时候炒了一波底，买回来一堆斐讯的设备，以tc1插线盒居多，但是随着斐讯线上服务的关闭，这些原本的智能插线盒变得不智能了，正好网上有网友开发了一波TC1的固件，正好自己也挺感兴趣，便开始折腾起了这些玩意儿。 作案工具 庆科EMW3031开发板 庆科EMW3165开发板 庆科MICOKIT-EXT上层扩展板 USB转TTL工具 JLINK仿真器 PS：3165和扩展板是在闲鱼直接50包邮收的，感觉赚得飞起。usb-ttl一开始不知道需要这个，反复看文档才发现差这玩意儿，5块的东西发了20的顺丰才送到。 开发生态以前从来没玩过如此高大上的玩意儿，这次就算拿到手也是一脸蒙蔽，不知从何下手，入手自闲鱼也没有任何资料，只好先翻一翻庆科的官网看看。 收集的部分有用的链接 庆科官网 开发者中心 官方论坛 开发者支持社区 启动到bootloader物理接线 123456789第一条接线 [用户串口] 对应驱动是USB-TTL的驱动 USB-SERIAL CH340 PC USB接口 =======&gt; USB-TTL =======&gt; 开发板UART接口 |—— GND |—— GND |—— RXD |—— TXD |—— TXD |—— RXD |—— 5V0 |—— 5V0 第二条接线 [调试串口] 对应驱动是开发板的驱动 USB Serial Port PC USB接口 =======&gt; 开发板microUsb接口 PS：这里也被卡了不少时间，原因就是不知道RXD和TXD需要反着接。官网文档里没有任何说明，我在USB-TTL的淘宝页面里找到的资料才提到这一点 驱动管理首先，我完全是个门外汉，我猜测这两驱动的作用可能是一样的，以前的外围设备都是通过COM口和PC相连接的，现在的电脑都没有COM口，于是需要一个将COM口转为USB口的设备。USB-TTL应该就是其中之一，所以才需要安装一个驱动来将USB口映射为虚拟的COM口供软件连接。至于开发板为何可以用microUsb直连电脑我猜测是开发板中内置了芯片来转换，因为我看了新平台MXKIT的说明文档，新平台中只需要一根线就可以同时接上两个接口，所以我做出了这个猜测。 软件连接官网教程 先将开发版上的MODULE SELECT拨动到BootLoader启动模式，即BOOT&#x3D;ON,STATUS&#x3D;OFF。 在其官网新文档的角落翻到了这个表格，根据表格内容在SecureCRT中建立连接 型号 BootloaderMFG产测信息 AT指令及透传 正常工作logCLI调试命令 EMW3031 Pin 9,Pin10,921600bps Pin 9,Pin10,115200bps Pin21,Pin22,115200bps EMW3060 Pin 9,Pin10,921600bps Pin 9,Pin10,115200bps Pin21,Pin22,115200bps EMW3080 Pin 9,Pin10,921600bps Pin 9,Pin10,115200bps Pin21,Pin22,115200bps EMW3162 Pin22,Pin23,921600bps Pin22,Pin23,115200bps Pin14,Pin4,115200bps EMW3165 Pin29,Pin30,921600bps Pin29,Pin30,115200bps Pin8,Pin12,115200bps EMW3166 Pin29,Pin30,921600bps Pin29,Pin30,115200bps Pin8,Pin12,115200bps EMW3239 Pin29,Pin30,921600bps Pin29,Pin30,115200bps Pin8,Pin12,115200bps 建立好连接后点一下开发板上的restart重启一下就能能看到日志了,如下图左边是用户日志，来自于microUsb(COM4)，右边是调试日志，来自于usb-ttl(COM9)，平时的debug时的日志也都输出到这里。 未完待续……….."},{"title":"[WSL2]子系统ubuntu安装jdk8","path":"[WSL2]子系统ubuntu安装jdk8/","text":"这是个大坑 平时装个JDK这么简单的事 在WSL上问题还真不少 安装环境12适用于 Linux 的 Windows 子系统:Ubuntu-18.04 (默认) 以前都是用的centos,直接yum localinstall ./jdk-???-linux-x64.rpm就可以安装本地的RPM包了。但是现在使用的Ubuntu，只能安装DEB包，查询了一下有三种安装方式： RPM包转制为DEB包 使用开箱即用的tar.gz并配置环境变量 使用ppa源安装 开始安装很明显使用ppa源安装更稳定不容易遇到问题，参考了此文章Install Oracle Java 8 (JDK8 and JRE8) in Ubuntu or Linux Mint 123456789101112131415sudo add-apt-repository ppa:webupd8team/java //添加PPA源sudo apt-get update //更新本地包sudo apt-get install oracle-java8-installer //安装JDK// 很遗憾报错了root@DESKTOP-UFOJIL7:/wsl_share# apt-get install oracle-java8-installerReading package lists... DoneBuilding dependency treeReading state information... DonePackage oracle-java8-installer is not available, but is referred to by another package.This may mean that the package is missing, has been obsoleted, oris only available from another sourceE: Package &#x27;oracle-java8-installer&#x27; has no installation candidate 在这里找到了答案Oracle-Java8-Installer: No installation candidate &gt; NOTE: This answer no longer works, as the WebUpd8 PPA has been deprecated since Oracle has changed licensing and access restrictions to the Oracle Java codebase. Details at http://www.webupd8.org/2014/03/how-to-install-oracle-java-8-in-debian.html 翻译一下 &gt;注意：此答案不再有效，因为WebUpd8 PPA已被弃用，因为Oracle已将许可和访问限制更改为Oracle Java代码库。 有关详细信息， 请访问http://www.webupd8.org/2014/03/how-to-install-oracle-java-8-in-debian.html 既然如此，那没啥办法只能手动安装一个了 手动配置首先下载一个jdk-8u221-linux-x64.tar.gz,拷贝到wsl_share中 12root@DESKTOP-UFOJIL7:/wsl_share# tar -zxvf ./jdk-8u221-linux-x64.tar.gz //首先解压root@DESKTOP-UFOJIL7:/wsl_share# vim ~/.bashrc //配置环境变量 12345// bashrc中追加以下内容export JAVA_HOME=/app/jdk1.8.0_221export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 12345678root@DESKTOP-UFOJIL7:/wsl_share# source ~/.bashrc //重新加载环境变量root@DESKTOP-UFOJIL7:/wsl_share# java -versionjava version &quot;1.8.0_221&quot;Java(TM) SE Runtime Environment (build 1.8.0_221-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)"},{"title":"[Centos]yum仓库配置及常用操作","path":"[Centos]yum仓库配置及常用操作/","text":"yum时不时抽风？仓库获取不到最新资源？先理解yum是怎么工作的吧！ 常用的储存库要注意的坑 储存库要启用了才有效 yum repo 只能显示已启用的储存库 显示全部需要yum repolist all 如果使用yum-config-manager配置仓库一定要记得保存 配置完后记得要yum makecache建立缓存，如果不放心可以先yum clean all 清除所有缓存 &gt; 上面的坑我全部踩了 命令 yum repolist all12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879Loaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirror.scalabledns.com * elrepo: repos.lax-noc.com * elrepo-extras: repos.lax-noc.com * elrepo-kernel: repos.lax-noc.com * extras: repos-lax.psychz.net * updates: repos-lax.psychz.netrepo id repo name status// 这些仓库应该是系统升级时留下来的C7.0.1406-base/x86_64 CentOS-7.0.1406 - Base disabledC7.0.1406-centosplus/x86_64 CentOS-7.0.1406 - CentOSPlus disabledC7.0.1406-extras/x86_64 CentOS-7.0.1406 - Extras disabledC7.0.1406-fasttrack/x86_64 CentOS-7.0.1406 - Fasttrack disabledC7.0.1406-updates/x86_64 CentOS-7.0.1406 - Updates disabledC7.1.1503-base/x86_64 CentOS-7.1.1503 - Base disabledC7.1.1503-centosplus/x86_64 CentOS-7.1.1503 - CentOSPlus disabledC7.1.1503-extras/x86_64 CentOS-7.1.1503 - Extras disabledC7.1.1503-fasttrack/x86_64 CentOS-7.1.1503 - Fasttrack disabledC7.1.1503-updates/x86_64 CentOS-7.1.1503 - Updates disabledC7.2.1511-base/x86_64 CentOS-7.2.1511 - Base disabledC7.2.1511-centosplus/x86_64 CentOS-7.2.1511 - CentOSPlus disabledC7.2.1511-extras/x86_64 CentOS-7.2.1511 - Extras disabledC7.2.1511-fasttrack/x86_64 CentOS-7.2.1511 - Fasttrack disabledC7.2.1511-updates/x86_64 CentOS-7.2.1511 - Updates disabledC7.3.1611-base/x86_64 CentOS-7.3.1611 - Base disabledC7.3.1611-centosplus/x86_64 CentOS-7.3.1611 - CentOSPlus disabledC7.3.1611-extras/x86_64 CentOS-7.3.1611 - Extras disabledC7.3.1611-fasttrack/x86_64 CentOS-7.3.1611 - Fasttrack disabledC7.3.1611-updates/x86_64 CentOS-7.3.1611 - Updates disabledC7.4.1708-base/x86_64 CentOS-7.4.1708 - Base disabledC7.4.1708-centosplus/x86_64 CentOS-7.4.1708 - CentOSPlus disabledC7.4.1708-extras/x86_64 CentOS-7.4.1708 - Extras disabledC7.4.1708-fasttrack/x86_64 CentOS-7.4.1708 - Fasttrack disabledC7.4.1708-updates/x86_64 CentOS-7.4.1708 - Updates disabledC7.5.1804-base/x86_64 CentOS-7.5.1804 - Base disabledC7.5.1804-centosplus/x86_64 CentOS-7.5.1804 - CentOSPlus disabledC7.5.1804-extras/x86_64 CentOS-7.5.1804 - Extras disabledC7.5.1804-fasttrack/x86_64 CentOS-7.5.1804 - Fasttrack disabledC7.5.1804-updates/x86_64 CentOS-7.5.1804 - Updates disabledC7.6.1810-base/x86_64 CentOS-7.6.1810 - Base disabledC7.6.1810-centosplus/x86_64 CentOS-7.6.1810 - CentOSPlus disabledC7.6.1810-extras/x86_64 CentOS-7.6.1810 - Extras disabledC7.6.1810-fasttrack/x86_64 CentOS-7.6.1810 - Fasttrack disabledC7.6.1810-updates/x86_64 CentOS-7.6.1810 - Updates disabled// centos7核心库 源码库和开发库的源就不开了base/7/x86_64 CentOS-7 - Base enabled: 10,096+1base-debuginfo/x86_64 CentOS-7 - Debuginfo disabledbase-source/7 CentOS-7 - Base Sources disabled// 看上去是多媒体相关的库 没桌面环境应该是用不上了c7-media CentOS-7 - Media disabled// 这个源主要是用来替换base源的，其中有不少包是base源的增强版// 但是如果开启这个源部分包可能会于base冲突 // 需要在base源中exclude 或者使用yum-plugin-priorities插件来保证兼容性// 引用WIKI: https://wiki.centos.org/zh/AdditionalResources/Repositories/CentOSPluscentosplus/7/x86_64 CentOS-7 - Plus disabledcentosplus-source/7 CentOS-7 - Plus Sources disabled// cr = Continuous Release 下次发布内容 相当于beta版了cr/7/x86_64 CentOS-7 - cr disabled// elrepo = The Community Enterprise Linux Repository// http://elrepo.org 从描述中可以看出是驱动包 如果有UI可能要开elrepo ELRepo.org Community Enterprise enabled: 147elrepo-extras ELRepo.org Community Enterprise enabled: 19elrepo-kernel ELRepo.org Community Enterprise enabled: 37elrepo-testing ELRepo.org Community Enterprise disabled// 这个源要开啊 EPEL仓库 相当多常用的软件都在里面// https://fedoraproject.org/epel/x86_64 Extra Packages for Enterprise Li disabledepel-debuginfo/x86_64 Extra Packages for Enterprise Li disabledepel-source/x86_64 Extra Packages for Enterprise Li disabledepel-testing/x86_64 Extra Packages for Enterprise Li disabledepel-testing-debuginfo/x86_64 Extra Packages for Enterprise Li disabledepel-testing-source/x86_64 Extra Packages for Enterprise Li disabledextras/7/x86_64 CentOS-7 - Extras enabled: 305extras-source/7 CentOS-7 - Extras Sources disabledfasttrack/7/x86_64 CentOS-7 - fasttrack disabledupdates/7/x86_64 CentOS-7 - Updates enabled: 733+5updates-source/7 CentOS-7 - Updates Sources disabledrepolist: 11,337 命令 yum-config-manager [yum配置管理器]1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980Loaded plugins: fastestmirrorUsage: yum-config-manager [options] [section ...]Options: Plugin Options: Yum Base Options: -h, --help show this help message and exit -t, --tolerant be tolerant of errors // 完全从系统缓存运行，不更新缓存 -C, --cacheonly run entirely from system cache, don&#x27;t update cache -c [config file], --config=[config file] config file location -R [minutes], --randomwait=[minutes] maximum command wait time -d [debug level], --debuglevel=[debug level] debugging output level --showduplicates show duplicates, in repos, in list/search commands -e [error level], --errorlevel=[error level] error output level --rpmverbosity=[debug level name] debugging output level for rpm -q, --quiet quiet operation -v, --verbose verbose operation -y, --assumeyes answer yes for all questions --assumeno answer no for all questions --version show Yum version and exit --installroot=[path] set install root --enablerepo=[repo] // 启用储存库 enable one or more repositories (wildcards allowed) --disablerepo=[repo] disable one or more repositories (wildcards allowed) -x [package], --exclude=[package] exclude package(s) by name or glob --disableexcludes=[repo] disable exclude from main, for a repo or for everything --disableincludes=[repo] disable includepkgs for a repo or for everything --obsoletes enable obsoletes processing during updates --noplugins disable Yum plugins --nogpgcheck disable gpg signature checking --disableplugin=[plugin] disable plugins by name --enableplugin=[plugin] enable plugins by name --skip-broken skip packages with depsolving problems --color=COLOR control whether color is used --releasever=RELEASEVER set value of $releasever in yum config and repo files --downloadonly don&#x27;t update, just download --downloaddir=DLDIR specifies an alternate directory to store packages --setopt=SETOPTS set arbitrary config and repo options --bugfix Include bugfix relevant packages, in updates --security Include security relevant packages, in updates --advisory=ADVS, --advisories=ADVS Include packages needed to fix the given advisory, in updates --bzs=BZS Include packages needed to fix the given BZ, in updates --cves=CVES Include packages needed to fix the given CVE, in updates --sec-severity=SEVS, --secseverity=SEVS Include security relevant packages matching the severity, in updates yum-config-manager options: // 保存当前设置 --save save the current options (useful with --setopt) // 启用仓库 (自动保存) --enable enable the specified repos (automatically saves) // 禁用仓库 (自动保存) --disable disable the specified repos (automatically saves) // 从文件或URL添加仓库 (并启用) --add-repo=ADDREPO add (and enable) the repo from the specified file or url 命令 yum1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495Loaded plugins: fastestmirrorUsage: yum [options] COMMANDList of Commands:check Check for problems in the rpmdbcheck-update Check for available package updatesclean Remove cached datadeplist List a package&#x27;s dependenciesdistribution-synchronization Synchronize installed packages to the latest available versionsdowngrade downgrade a packageerase Remove a package or packages from your systemfs Acts on the filesystem data of the host, mainly for removing docs/lanuages for minimal hosts.fssnapshot Creates filesystem snapshots, or lists/deletes current snapshots.groups Display, or use, the groups informationhelp Display a helpful usage messagehistory Display, or use, the transaction historyinfo Display details about a package or group of packagesinstall Install a package or packages on your systemlist List a package or groups of packagesload-transaction load a saved transaction from filenamemakecache Generate the metadata cacheprovides Find what package provides the given valuereinstall reinstall a packagerepo-pkgs Treat a repo. as a group of packages, so we can install/remove all of themrepolist Display the configured software repositoriessearch Search package details for the given stringshell Run an interactive yum shellswap Simple way to swap packages, instead of using shellupdate Update a package or packages on your systemupdate-minimal Works like upgrade, but goes to the &#x27;newest&#x27; package match which fixes a problem that affects your systemupdateinfo Acts on repository update informationupgrade Update packages taking obsoletes into accountversion Display a version for the machine and/or available repos.Options: -h, --help show this help message and exit -t, --tolerant be tolerant of errors -C, --cacheonly run entirely from system cache, don&#x27;t update cache -c [config file], --config=[config file] config file location -R [minutes], --randomwait=[minutes] maximum command wait time -d [debug level], --debuglevel=[debug level] debugging output level --showduplicates show duplicates, in repos, in list/search commands -e [error level], --errorlevel=[error level] error output level --rpmverbosity=[debug level name] debugging output level for rpm -q, --quiet quiet operation -v, --verbose verbose operation -y, --assumeyes answer yes for all questions --assumeno answer no for all questions --version show Yum version and exit --installroot=[path] set install root --enablerepo=[repo] enable one or more repositories (wildcards allowed) --disablerepo=[repo] disable one or more repositories (wildcards allowed) -x [package], --exclude=[package] exclude package(s) by name or glob --disableexcludes=[repo] disable exclude from main, for a repo or for everything --disableincludes=[repo] disable includepkgs for a repo or for everything --obsoletes enable obsoletes processing during updates --noplugins disable Yum plugins --nogpgcheck disable gpg signature checking --disableplugin=[plugin] disable plugins by name --enableplugin=[plugin] enable plugins by name --skip-broken skip packages with depsolving problems --color=COLOR control whether color is used --releasever=RELEASEVER set value of $releasever in yum config and repo files --downloadonly don&#x27;t update, just download --downloaddir=DLDIR specifies an alternate directory to store packages --setopt=SETOPTS set arbitrary config and repo options --bugfix Include bugfix relevant packages, in updates --security Include security relevant packages, in updates --advisory=ADVS, --advisories=ADVS Include packages needed to fix the given advisory, in updates --bzs=BZS Include packages needed to fix the given BZ, in updates --cves=CVES Include packages needed to fix the given CVE, in updates --sec-severity=SEVS, --secseverity=SEVS Include security relevant packages matching the severity, in updates Plugin Options:"},{"title":"Hexo部署GitMent评论","path":"Hexo部署GitMent评论/","text":"由于站点迁移导致的数据丢失，该文章已做归档处理之前还没换主题的时候就是这样手动配置的，现在gitment都没人用了git-talk比较方便 GitMent简介 Gitment是一个基于GitHub Issues的评论系统，他使用一个Github Repository的Issues区作为评论的存储区。支持在前端直接引入，不需要任何后端代码。可以在页面进行登录、查看、评论、点赞等操作，同时有完整的 Markdown &#x2F; GFM 和代码高亮支持。尤为适合各种基于 GitHub Pages 的静态博客或项目页面。 Initialize Comments 时提示 Error: Validation Failed出现问题 部署完成后点击初始化按钮后alert:”Error: Validation Failed” 图1.Error: Validation Failed 查询资料 首先查阅了一下资料,找到了 GitMent的issues ： &gt; 地址 https://github.com/imsun/gitment/issues/118 原因分析 GitHub Issues中新建label时LabelName长度不能超过50，但是在GitMent中是以页面url(window.location.pathname)作为唯一标识来创建Label的，当我们以中文作为文章标题时，中文将被转义，转义后的url超过了50字符长度的限制，引起报错。 图2.LabelName长度过长 解决方式： 缩短标题长度，并尽量少用中文标题 寻找较短的具有唯一性的参数作为Issues的LabelName 图3.参数替换前后对比 很明显只能寻找其他参数来代替URL作为ID了，在这里我们使用网页标题（document.title）作为ID。 错误修正&nbsp;#######** hexo-theme-yilia主题 ** 该主题的gitment配置文件位于${hexo_root}&#x2F;themes&#x2F;hexo-theme-yilia&#x2F;layout&#x2F;_partial&#x2F;post下 修改gitment.ejs: 图4.gitment.ejs ** hexo-theme-next主题 ** 该主题的gitment配置文件位于${hexo_root}&#x2F;themes&#x2F;hexo-theme-next&#x2F;layout&#x2F;_third-party&#x2F;comments下 修改gitment.swig: 图5.gitment.swig 效果一览 修改后成功初始化，Issus中出现了对应文章的记录，blog中可以正常的发布评论了。 图6.GitMent效果 图7.GitHub效果"}]